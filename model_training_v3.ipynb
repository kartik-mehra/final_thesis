{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_MODEL = 'inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import log_metric, log_param, log_artifact\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/22 11:40:43 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n",
      "2025/02/22 11:40:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/02/22 11:40:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2025/02/22 11:40:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/02/22 11:40:43 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/837799944280473961/5690c2ea4d0841cda482d1b25c7f7a68/artifacts\n",
      "http://127.0.0.1:5000/\n"
     ]
    }
   ],
   "source": [
    "remote_server_uri = \"http://127.0.0.1:5000/\"  # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "experiment_name = 'Men_Clothing_Image_recommendation_v4'\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "# Forcing an end_run() to prevent \n",
    "#    https://github.com/mlflow/mlflow/issues/1335 \n",
    "#    https://github.com/mlflow/mlflow/issues/608\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "artifact_path = mlflow.get_artifact_uri()\n",
    "uri = mlflow.tracking.get_tracking_uri()\n",
    "print(artifact_path)\n",
    "print(uri)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient(mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_parquet(f'../Dataset/nodes_without_image.parquet')\n",
    "# edges = pd.read_parquet(f'../processed/{IMAGE_MODEL}/edges.parquet',engine='pyarrow')\n",
    "umap_dt = {'n_components':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g,train_pos_g,test_pos_g,train_neg_g,test_neg_g,cols_needed = create_model_data(IMAGE_MODEL,True,0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Only edges information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_needed = ['asin', 'price_power_transform', 'also_buy', 'avg_rating',\n",
    "       'no_of_ratings', 'rank_num_power_transform', 'label_1', 'label_2',\n",
    "       'label_3', 'label_4', 'label_5', 'label_6', 'label_7', 'label_8',\n",
    "       'label_9', 'label_10', 'label_11', 'label_12', 'label_13',\n",
    "       'cluster_group_cluster 0', 'cluster_group_cluster 1',\n",
    "       'cluster_group_cluster 2', 'cluster_group_cluster 3',\n",
    "       'cluster_group_cluster 4', 'cluster_group_cluster 5',\n",
    "       'cluster_group_cluster 6', 'cluster_group_cluster 7',\n",
    "       'cluster_group_cluster 8', 'cluster_group_cluster 9',\n",
    "       'clothing_type_Active', 'clothing_type_Jackets & Coats',\n",
    "       'clothing_type_Jeans', 'clothing_type_Pants', 'clothing_type_Shirts',\n",
    "       'clothing_type_Shorts', 'clothing_type_Sleep & Lounge',\n",
    "       'clothing_type_Socks', 'clothing_type_Swim', 'clothing_type_Underwear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in nodes.columns:\n",
    "#     nodes[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_model_data() got an unexpected keyword argument 'cols_needed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m IMAGE_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minception\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMAGE_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maggregator_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh_feats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#{'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mIMAGE_MODEL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_same_values_ndata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mimage_included\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mumap_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_components\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_neighbors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_dist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43monly_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mskip_ndata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_bidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Masters\\notebooks\\util.py:290\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(mlflow, image_model, run_name, n_epochs, model_params, image_included, split_ratio, umap_dt, k, patience, only_image, use_bidirectional, skip_ndata, cols_needed)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(mlflow,image_model,run_name,n_epochs,model_params,image_included \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,split_ratio \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,umap_dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,only_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,use_bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,skip_ndata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,cols_needed \u001b[38;5;241m=\u001b[39m []):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39mrun_name) \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;66;03m# PATH = './model_checkpoints'\u001b[39;00m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;66;03m# if os.path.exists(PATH):\u001b[39;00m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;66;03m#     shutil.rmtree(PATH)\u001b[39;00m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;66;03m# if not os.path.exists(PATH):\u001b[39;00m\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;66;03m#     os.makedirs(PATH)\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m         g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g,train_pos_g,test_pos_g,train_neg_g,test_neg_g,cols_needed \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_included\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43mumap_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43monly_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_bidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskip_ndata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_ndata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcols_needed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;66;03m# Move the graph to the device\u001b[39;00m\n\u001b[0;32m    293\u001b[0m         train_g \u001b[38;5;241m=\u001b[39m train_g\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: create_model_data() got an unexpected keyword argument 'cols_needed'"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'mean', 'dropout': 0, 'h_feats': 16, 'lr': 0.01},#{'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_same_values_ndata',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=False,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=False,skip_ndata=True,use_bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node data shape : (10867, 39)\n",
      "Edges data shape : (20554, 2)\n",
      "Size of Input features : 1\n",
      "node features shape : torch.Size([10867, 1])\n",
      "14388 6166\n",
      "In epoch 0, loss: 1.420879602432251\n",
      "Epoch 0: Best model saved min loss 1.420879602432251\n",
      "Epoch 1: Best model saved min loss 1.2001255750656128\n",
      "Epoch 2: Best model saved min loss 1.0127512216567993\n",
      "Epoch 3: Best model saved min loss 0.8594118356704712\n",
      "Epoch 4: Best model saved min loss 0.743012547492981\n",
      "In epoch 5, loss: 0.6625522971153259\n",
      "Epoch 5: Best model saved min loss 0.6625522971153259\n",
      "Epoch 6: Best model saved min loss 0.6057570576667786\n",
      "Epoch 7: Best model saved min loss 0.5590574145317078\n",
      "Epoch 8: Best model saved min loss 0.5177666544914246\n",
      "Epoch 9: Best model saved min loss 0.4829390347003937\n",
      "In epoch 10, loss: 0.45662063360214233\n",
      "Epoch 10: Best model saved min loss 0.45662063360214233\n",
      "Epoch 11: Best model saved min loss 0.4390198588371277\n",
      "Epoch 12: Best model saved min loss 0.42797043919563293\n",
      "Epoch 13: Best model saved min loss 0.4204283356666565\n",
      "Epoch 14: Best model saved min loss 0.4139748513698578\n",
      "In epoch 15, loss: 0.40759599208831787\n",
      "Epoch 15: Best model saved min loss 0.40759599208831787\n",
      "Epoch 16: Best model saved min loss 0.40137234330177307\n",
      "Epoch 17: Best model saved min loss 0.39587563276290894\n",
      "Epoch 18: Best model saved min loss 0.3915691375732422\n",
      "Epoch 19: Best model saved min loss 0.3884601891040802\n",
      "In epoch 20, loss: 0.38610777258872986\n",
      "Epoch 20: Best model saved min loss 0.38610777258872986\n",
      "Epoch 21: Best model saved min loss 0.38389527797698975\n",
      "Epoch 22: Best model saved min loss 0.381337434053421\n",
      "Epoch 23: Best model saved min loss 0.37825384736061096\n",
      "Epoch 24: Best model saved min loss 0.37480610609054565\n",
      "In epoch 25, loss: 0.37132951617240906\n",
      "Epoch 25: Best model saved min loss 0.37132951617240906\n",
      "Epoch 26: Best model saved min loss 0.3682307004928589\n",
      "Epoch 27: Best model saved min loss 0.36568209528923035\n",
      "Epoch 28: Best model saved min loss 0.3636001646518707\n",
      "Epoch 29: Best model saved min loss 0.36172789335250854\n",
      "In epoch 30, loss: 0.3598119914531708\n",
      "Epoch 30: Best model saved min loss 0.3598119914531708\n",
      "Epoch 31: Best model saved min loss 0.3577345311641693\n",
      "Epoch 32: Best model saved min loss 0.35555437207221985\n",
      "Epoch 33: Best model saved min loss 0.3534466624259949\n",
      "Epoch 34: Best model saved min loss 0.35158348083496094\n",
      "In epoch 35, loss: 0.350042462348938\n",
      "Epoch 35: Best model saved min loss 0.350042462348938\n",
      "Epoch 36: Best model saved min loss 0.34877902269363403\n",
      "Epoch 37: Best model saved min loss 0.34766536951065063\n",
      "Epoch 38: Best model saved min loss 0.3465714156627655\n",
      "Epoch 39: Best model saved min loss 0.3454386293888092\n",
      "In epoch 40, loss: 0.34429556131362915\n",
      "Epoch 40: Best model saved min loss 0.34429556131362915\n",
      "Epoch 41: Best model saved min loss 0.3432157039642334\n",
      "Epoch 42: Best model saved min loss 0.34225475788116455\n",
      "Epoch 43: Best model saved min loss 0.3413972556591034\n",
      "Epoch 44: Best model saved min loss 0.3405683934688568\n",
      "In epoch 45, loss: 0.33967870473861694\n",
      "Epoch 45: Best model saved min loss 0.33967870473861694\n",
      "Epoch 46: Best model saved min loss 0.3386843502521515\n",
      "Epoch 47: Best model saved min loss 0.3376004993915558\n",
      "Epoch 48: Best model saved min loss 0.3364904224872589\n",
      "Epoch 49: Best model saved min loss 0.3354165256023407\n",
      "In epoch 50, loss: 0.3344161808490753\n",
      "Epoch 50: Best model saved min loss 0.3344161808490753\n",
      "Epoch 51: Best model saved min loss 0.3334665596485138\n",
      "Epoch 52: Best model saved min loss 0.33252397179603577\n",
      "Epoch 53: Best model saved min loss 0.3315609395503998\n",
      "Epoch 54: Best model saved min loss 0.33058515191078186\n",
      "In epoch 55, loss: 0.32964423298835754\n",
      "Epoch 55: Best model saved min loss 0.32964423298835754\n",
      "Epoch 56: Best model saved min loss 0.32879310846328735\n",
      "Epoch 57: Best model saved min loss 0.3280366361141205\n",
      "Epoch 58: Best model saved min loss 0.3273467719554901\n",
      "Epoch 59: Best model saved min loss 0.32669490575790405\n",
      "In epoch 60, loss: 0.32608217000961304\n",
      "Epoch 60: Best model saved min loss 0.32608217000961304\n",
      "Epoch 61: Best model saved min loss 0.32553356885910034\n",
      "Epoch 62: Best model saved min loss 0.32506442070007324\n",
      "Epoch 63: Best model saved min loss 0.324655145406723\n",
      "Epoch 64: Best model saved min loss 0.32426127791404724\n",
      "In epoch 65, loss: 0.32384467124938965\n",
      "Epoch 65: Best model saved min loss 0.32384467124938965\n",
      "Epoch 66: Best model saved min loss 0.323404461145401\n",
      "Epoch 67: Best model saved min loss 0.32297030091285706\n",
      "Epoch 68: Best model saved min loss 0.32255950570106506\n",
      "Epoch 69: Best model saved min loss 0.3221700191497803\n",
      "In epoch 70, loss: 0.32179221510887146\n",
      "Epoch 70: Best model saved min loss 0.32179221510887146\n",
      "Epoch 71: Best model saved min loss 0.32142162322998047\n",
      "Epoch 72: Best model saved min loss 0.3210679888725281\n",
      "Epoch 73: Best model saved min loss 0.32073962688446045\n",
      "Epoch 74: Best model saved min loss 0.3204329013824463\n",
      "In epoch 75, loss: 0.32013392448425293\n",
      "Epoch 75: Best model saved min loss 0.32013392448425293\n",
      "Epoch 76: Best model saved min loss 0.31983399391174316\n",
      "Epoch 77: Best model saved min loss 0.3195391297340393\n",
      "Epoch 78: Best model saved min loss 0.31925415992736816\n",
      "Epoch 79: Best model saved min loss 0.31897982954978943\n",
      "In epoch 80, loss: 0.3187084197998047\n",
      "Epoch 80: Best model saved min loss 0.3187084197998047\n",
      "Epoch 81: Best model saved min loss 0.3184365928173065\n",
      "Epoch 82: Best model saved min loss 0.3181705176830292\n",
      "Epoch 83: Best model saved min loss 0.3179165720939636\n",
      "Epoch 84: Best model saved min loss 0.31767532229423523\n",
      "In epoch 85, loss: 0.31744128465652466\n",
      "Epoch 85: Best model saved min loss 0.31744128465652466\n",
      "Epoch 86: Best model saved min loss 0.31721240282058716\n",
      "Epoch 87: Best model saved min loss 0.3169923722743988\n",
      "Epoch 88: Best model saved min loss 0.316784530878067\n",
      "Epoch 89: Best model saved min loss 0.31658419966697693\n",
      "In epoch 90, loss: 0.3163873851299286\n",
      "Epoch 90: Best model saved min loss 0.3163873851299286\n",
      "Epoch 91: Best model saved min loss 0.31619471311569214\n",
      "Epoch 92: Best model saved min loss 0.3160090446472168\n",
      "Epoch 93: Best model saved min loss 0.315830260515213\n",
      "Epoch 94: Best model saved min loss 0.315656840801239\n",
      "In epoch 95, loss: 0.31548622250556946\n",
      "Epoch 95: Best model saved min loss 0.31548622250556946\n",
      "Epoch 96: Best model saved min loss 0.31531959772109985\n",
      "Epoch 97: Best model saved min loss 0.3151590824127197\n",
      "Epoch 98: Best model saved min loss 0.31500309705734253\n",
      "Epoch 99: Best model saved min loss 0.3148497939109802\n",
      "Train AUC 0.9503598349174328\n",
      "Test AUC 0.9610758079342115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 6163.45it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 8693.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.24386655199397875\n",
      "Test recall@100 0.2679001903150772\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'mean', 'dropout': 0, 'h_feats': 16, 'lr': 0.01},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_price_feature',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=False,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=False,skip_ndata=True,use_bidirectional=False,cols_needed=['price_power_transform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2678],\n",
       "        [ 1.0752],\n",
       "        [ 1.0752],\n",
       "        ...,\n",
       "        [-0.8801],\n",
       "        [ 0.8022],\n",
       "        [-0.4471]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node data shape : (10867, 39)\n",
      "Edges data shape : (20554, 2)\n",
      "Size of Input features : 37\n",
      "node features shape : torch.Size([10867, 37])\n",
      "##########################\n",
      "Converting to biderctional Graph\n",
      "##########################\n",
      "27998 11999\n",
      "In epoch 0, loss: 12.481778144836426\n",
      "Epoch 0: Best model saved min loss 12.481778144836426\n",
      "Epoch 1: Best model saved min loss 4.026902675628662\n",
      "Epoch 2: Best model saved min loss 0.9980332851409912\n",
      "Epoch 3: Best model saved min loss 0.5205588340759277\n",
      "Epoch 4: Best model saved min loss 0.4308769404888153\n",
      "In epoch 5, loss: 0.4118104875087738\n",
      "Epoch 5: Best model saved min loss 0.4118104875087738\n",
      "Epoch 7: Best model saved min loss 0.40738698840141296\n",
      "Epoch 8: Best model saved min loss 0.3867255449295044\n",
      "Epoch 9: Best model saved min loss 0.3637147843837738\n",
      "In epoch 10, loss: 0.347954124212265\n",
      "Epoch 10: Best model saved min loss 0.347954124212265\n",
      "Epoch 11: Best model saved min loss 0.33972927927970886\n",
      "Epoch 12: Best model saved min loss 0.33568254113197327\n",
      "Epoch 13: Best model saved min loss 0.33090585470199585\n",
      "Epoch 14: Best model saved min loss 0.3234426975250244\n",
      "In epoch 15, loss: 0.3148862421512604\n",
      "Epoch 15: Best model saved min loss 0.3148862421512604\n",
      "Epoch 16: Best model saved min loss 0.30715256929397583\n",
      "Epoch 17: Best model saved min loss 0.3013382852077484\n",
      "Epoch 18: Best model saved min loss 0.2974076569080353\n",
      "Epoch 19: Best model saved min loss 0.2941857576370239\n",
      "In epoch 20, loss: 0.29031071066856384\n",
      "Epoch 20: Best model saved min loss 0.29031071066856384\n",
      "Epoch 21: Best model saved min loss 0.28579574823379517\n",
      "Epoch 22: Best model saved min loss 0.2816440165042877\n",
      "Epoch 23: Best model saved min loss 0.27942097187042236\n",
      "Epoch 24: Best model saved min loss 0.2790985107421875\n",
      "In epoch 25, loss: 0.27838459610939026\n",
      "Epoch 25: Best model saved min loss 0.27838459610939026\n",
      "Epoch 26: Best model saved min loss 0.2752721905708313\n",
      "Epoch 27: Best model saved min loss 0.2730542719364166\n",
      "In epoch 30, loss: 0.2730611264705658\n",
      "Epoch 31: Best model saved min loss 0.271575927734375\n",
      "Epoch 34: Best model saved min loss 0.2707163691520691\n",
      "In epoch 35, loss: 0.2703101336956024\n",
      "Epoch 35: Best model saved min loss 0.2703101336956024\n",
      "Epoch 37: Best model saved min loss 0.27010971307754517\n",
      "Epoch 38: Best model saved min loss 0.26932501792907715\n",
      "In epoch 40, loss: 0.2696378231048584\n",
      "Epoch 41: Best model saved min loss 0.26910483837127686\n",
      "Epoch 42: Best model saved min loss 0.2686624825000763\n",
      "Epoch 44: Best model saved min loss 0.2686302661895752\n",
      "In epoch 45, loss: 0.2679992914199829\n",
      "Epoch 45: Best model saved min loss 0.2679992914199829\n",
      "Epoch 46: Best model saved min loss 0.267536461353302\n",
      "Epoch 47: Best model saved min loss 0.2675049901008606\n",
      "Epoch 48: Best model saved min loss 0.26715323328971863\n",
      "Epoch 49: Best model saved min loss 0.2665807008743286\n",
      "In epoch 50, loss: 0.2665555775165558\n",
      "Epoch 50: Best model saved min loss 0.2665555775165558\n",
      "Epoch 51: Best model saved min loss 0.26649022102355957\n",
      "Epoch 52: Best model saved min loss 0.2661755084991455\n",
      "Epoch 53: Best model saved min loss 0.2661267817020416\n",
      "Epoch 54: Best model saved min loss 0.2659827768802643\n",
      "In epoch 55, loss: 0.2656336724758148\n",
      "Epoch 55: Best model saved min loss 0.2656336724758148\n",
      "Epoch 56: Best model saved min loss 0.2654327154159546\n",
      "Epoch 57: Best model saved min loss 0.2652748227119446\n",
      "Epoch 58: Best model saved min loss 0.2650182843208313\n",
      "In epoch 60, loss: 0.2648501396179199\n",
      "Epoch 60: Best model saved min loss 0.2648501396179199\n",
      "Epoch 62: Best model saved min loss 0.26481935381889343\n",
      "Epoch 63: Best model saved min loss 0.2646788954734802\n",
      "Epoch 64: Best model saved min loss 0.26458802819252014\n",
      "In epoch 65, loss: 0.26442503929138184\n",
      "Epoch 65: Best model saved min loss 0.26442503929138184\n",
      "Epoch 66: Best model saved min loss 0.2642415761947632\n",
      "Epoch 67: Best model saved min loss 0.26417580246925354\n",
      "Epoch 68: Best model saved min loss 0.26410165429115295\n",
      "Epoch 69: Best model saved min loss 0.263925701379776\n",
      "In epoch 70, loss: 0.26390060782432556\n",
      "Epoch 70: Best model saved min loss 0.26390060782432556\n",
      "Epoch 71: Best model saved min loss 0.2637351453304291\n",
      "Epoch 72: Best model saved min loss 0.26362597942352295\n",
      "Epoch 73: Best model saved min loss 0.263595312833786\n",
      "Epoch 74: Best model saved min loss 0.2635022699832916\n",
      "In epoch 75, loss: 0.2634540796279907\n",
      "Epoch 75: Best model saved min loss 0.2634540796279907\n",
      "Epoch 76: Best model saved min loss 0.2633720636367798\n",
      "Epoch 77: Best model saved min loss 0.2632782459259033\n",
      "Epoch 78: Best model saved min loss 0.26322150230407715\n",
      "Epoch 79: Best model saved min loss 0.26320895552635193\n",
      "In epoch 80, loss: 0.26308175921440125\n",
      "Epoch 80: Best model saved min loss 0.26308175921440125\n",
      "Epoch 81: Best model saved min loss 0.2630334496498108\n",
      "Epoch 82: Best model saved min loss 0.26298606395721436\n",
      "Epoch 83: Best model saved min loss 0.26288050413131714\n",
      "Epoch 84: Best model saved min loss 0.26281481981277466\n",
      "In epoch 85, loss: 0.2627614438533783\n",
      "Epoch 85: Best model saved min loss 0.2627614438533783\n",
      "Epoch 86: Best model saved min loss 0.2626684606075287\n",
      "Epoch 87: Best model saved min loss 0.26260796189308167\n",
      "Epoch 88: Best model saved min loss 0.2625088691711426\n",
      "Epoch 89: Best model saved min loss 0.26250094175338745\n",
      "In epoch 90, loss: 0.26241835951805115\n",
      "Epoch 90: Best model saved min loss 0.26241835951805115\n",
      "Epoch 91: Best model saved min loss 0.26238930225372314\n",
      "Epoch 93: Best model saved min loss 0.2622425854206085\n",
      "In epoch 95, loss: 0.2621198296546936\n",
      "Epoch 95: Best model saved min loss 0.2621198296546936\n",
      "Epoch 96: Best model saved min loss 0.2620736062526703\n",
      "Epoch 97: Best model saved min loss 0.26202109456062317\n",
      "Epoch 98: Best model saved min loss 0.26196497678756714\n",
      "Epoch 99: Best model saved min loss 0.2619301378726959\n",
      "Train AUC 0.9648321727050657\n",
      "Test AUC 0.9378087706436575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 7763.40it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 7879.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.6104862324571897\n",
      "Test recall@100 0.5978765462443362\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_no_features',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=False,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=False,skip_ndata=True,use_bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     1,     1,  ..., 10864, 10865, 10866]),\n",
       " tensor([7018, 2719, 5903,  ..., 8566, 3451, 8679]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_MODEL = 'inception'\n",
    "# temp = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "#                                                                                                                                           run_name=f'{IMAGE_MODEL}_best_tuned_model',\n",
    "#                                                                                                                                           n_epochs=1000,\n",
    "#                                                                                                                                           image_included=False,\n",
    "#                                                                                                                                           split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using any image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14388 6166\n",
      "In epoch 0, loss: 6340.31298828125\n",
      "Epoch 0: Best model saved min loss 6340.31298828125\n",
      "Epoch 1: Best model saved min loss 5934.5390625\n",
      "Epoch 2: Best model saved min loss 3804.020751953125\n",
      "Epoch 4: Best model saved min loss 2490.83447265625\n",
      "In epoch 5, loss: 1638.9195556640625\n",
      "Epoch 5: Best model saved min loss 1638.9195556640625\n",
      "Epoch 8: Best model saved min loss 1068.1566162109375\n",
      "In epoch 10, loss: 1489.905517578125\n",
      "Epoch 12: Best model saved min loss 796.4181518554688\n",
      "Epoch 13: Best model saved min loss 389.5713806152344\n",
      "In epoch 15, loss: 378.2738037109375\n",
      "Epoch 15: Best model saved min loss 378.2738037109375\n",
      "Epoch 16: Best model saved min loss 267.88397216796875\n",
      "Epoch 17: Best model saved min loss 204.0205535888672\n",
      "Epoch 18: Best model saved min loss 144.7747039794922\n",
      "In epoch 20, loss: 212.8731231689453\n",
      "Epoch 21: Best model saved min loss 137.2342529296875\n",
      "Epoch 23: Best model saved min loss 103.94027709960938\n",
      "Epoch 24: Best model saved min loss 59.29706954956055\n",
      "In epoch 25, loss: 52.854820251464844\n",
      "Epoch 25: Best model saved min loss 52.854820251464844\n",
      "Epoch 27: Best model saved min loss 45.9890251159668\n",
      "Epoch 28: Best model saved min loss 33.353782653808594\n",
      "Epoch 29: Best model saved min loss 26.090797424316406\n",
      "In epoch 30, loss: 42.25118637084961\n",
      "Epoch 31: Best model saved min loss 15.176373481750488\n",
      "In epoch 35, loss: 14.055188179016113\n",
      "Epoch 35: Best model saved min loss 14.055188179016113\n",
      "Epoch 36: Best model saved min loss 6.91602897644043\n",
      "Epoch 38: Best model saved min loss 6.793979644775391\n",
      "Epoch 39: Best model saved min loss 6.570816993713379\n",
      "In epoch 40, loss: 4.9437408447265625\n",
      "Epoch 40: Best model saved min loss 4.9437408447265625\n",
      "Epoch 42: Best model saved min loss 3.497927188873291\n",
      "In epoch 45, loss: 1.7458341121673584\n",
      "Epoch 45: Best model saved min loss 1.7458341121673584\n",
      "Epoch 48: Best model saved min loss 1.2574156522750854\n",
      "In epoch 50, loss: 1.7592716217041016\n",
      "In epoch 55, loss: 0.9466205835342407\n",
      "Epoch 55: Best model saved min loss 0.9466205835342407\n",
      "Epoch 57: Best model saved min loss 0.766564667224884\n",
      "In epoch 60, loss: 0.923307478427887\n",
      "Epoch 63: Best model saved min loss 0.6753435730934143\n",
      "In epoch 65, loss: 1.2994998693466187\n",
      "Epoch 67: Best model saved min loss 0.5156918168067932\n",
      "In epoch 70, loss: 0.6606683135032654\n",
      "In epoch 75, loss: 0.7212071418762207\n",
      "Epoch 77: Best model saved min loss 0.399518758058548\n",
      "In epoch 80, loss: 0.5432999730110168\n",
      "Epoch 84: Best model saved min loss 0.39231494069099426\n",
      "In epoch 85, loss: 0.5833853483200073\n",
      "In epoch 90, loss: 0.5586856007575989\n",
      "In epoch 95, loss: 0.48165303468704224\n",
      "In epoch 100, loss: 0.6914713978767395\n",
      "Epoch 103: Best model saved min loss 0.3857314884662628\n",
      "Epoch 104: Best model saved min loss 0.3476368188858032\n",
      "In epoch 105, loss: 0.34111353754997253\n",
      "Epoch 105: Best model saved min loss 0.34111353754997253\n",
      "In epoch 110, loss: 0.3088809847831726\n",
      "Epoch 110: Best model saved min loss 0.3088809847831726\n",
      "In epoch 115, loss: 0.3706909418106079\n",
      "Epoch 117: Best model saved min loss 0.3085279166698456\n",
      "In epoch 120, loss: 0.44813311100006104\n",
      "In epoch 125, loss: 0.4730425477027893\n",
      "In epoch 130, loss: 0.35181111097335815\n",
      "In epoch 135, loss: 0.36258214712142944\n",
      "In epoch 140, loss: 0.3257398009300232\n",
      "Epoch 141: Best model saved min loss 0.3049989640712738\n",
      "In epoch 145, loss: 0.46593502163887024\n",
      "In epoch 150, loss: 0.33959490060806274\n",
      "Epoch 152: Best model saved min loss 0.2949461042881012\n",
      "In epoch 155, loss: 0.3209957480430603\n",
      "In epoch 160, loss: 0.28768762946128845\n",
      "Epoch 160: Best model saved min loss 0.28768762946128845\n",
      "In epoch 165, loss: 0.32772138714790344\n",
      "Epoch 168: Best model saved min loss 0.28596246242523193\n",
      "In epoch 170, loss: 0.29568544030189514\n",
      "In epoch 175, loss: 0.3441457748413086\n",
      "In epoch 180, loss: 0.30111879110336304\n",
      "In epoch 185, loss: 0.3135014474391937\n",
      "In epoch 190, loss: 0.2815306782722473\n",
      "Epoch 190: Best model saved min loss 0.2815306782722473\n",
      "In epoch 195, loss: 0.2834469974040985\n",
      "In epoch 200, loss: 0.27993956208229065\n",
      "Epoch 200: Best model saved min loss 0.27993956208229065\n",
      "In epoch 205, loss: 0.30811256170272827\n",
      "In epoch 210, loss: 0.28429466485977173\n",
      "In epoch 215, loss: 0.28809061646461487\n",
      "In epoch 220, loss: 0.2919151782989502\n",
      "In epoch 225, loss: 0.290569931268692\n",
      "Epoch 228: Best model saved min loss 0.2780281603336334\n",
      "In epoch 230, loss: 0.2942908704280853\n",
      "In epoch 235, loss: 0.2804156243801117\n",
      "In epoch 240, loss: 0.27868127822875977\n",
      "In epoch 245, loss: 0.2835099697113037\n",
      "In epoch 250, loss: 0.27876701951026917\n",
      "In epoch 255, loss: 0.2815040647983551\n",
      "In epoch 260, loss: 0.2790030241012573\n",
      "Epoch 261: Best model saved min loss 0.27782750129699707\n",
      "In epoch 265, loss: 0.2799316644668579\n",
      "In epoch 270, loss: 0.2797897756099701\n",
      "In epoch 275, loss: 0.2802674472332001\n",
      "In epoch 280, loss: 0.280413955450058\n",
      "Epoch 282: Best model saved min loss 0.2777777314186096\n",
      "In epoch 285, loss: 0.28126487135887146\n",
      "In epoch 290, loss: 0.28168028593063354\n",
      "Epoch 291: Best model saved min loss 0.2769990861415863\n",
      "In epoch 295, loss: 0.2793089747428894\n",
      "In epoch 300, loss: 0.2804557681083679\n",
      "In epoch 305, loss: 0.2794906198978424\n",
      "In epoch 310, loss: 0.28397753834724426\n",
      "In epoch 315, loss: 0.27908259630203247\n",
      "In epoch 320, loss: 0.2785015404224396\n",
      "In epoch 325, loss: 0.27719613909721375\n",
      "In epoch 330, loss: 0.28110605478286743\n",
      "In epoch 335, loss: 0.277719646692276\n",
      "In epoch 340, loss: 0.27770620584487915\n",
      "In epoch 345, loss: 0.27784430980682373\n",
      "In epoch 350, loss: 0.2781771421432495\n",
      "In epoch 355, loss: 0.279285192489624\n",
      "In epoch 360, loss: 0.27833041548728943\n",
      "In epoch 365, loss: 0.27745550870895386\n",
      "Epoch 366: Best model saved min loss 0.27655142545700073\n",
      "In epoch 370, loss: 0.2765817642211914\n",
      "In epoch 375, loss: 0.2776744067668915\n",
      "In epoch 380, loss: 0.27928903698921204\n",
      "In epoch 385, loss: 0.27734702825546265\n",
      "In epoch 390, loss: 0.2780870199203491\n",
      "In epoch 395, loss: 0.27754276990890503\n",
      "In epoch 400, loss: 0.277569979429245\n",
      "In epoch 405, loss: 0.27750396728515625\n",
      "In epoch 410, loss: 0.2767989933490753\n",
      "In epoch 415, loss: 0.2772512435913086\n",
      "Epoch 417: Best model saved min loss 0.2764422595500946\n",
      "In epoch 420, loss: 0.27611809968948364\n",
      "Epoch 420: Best model saved min loss 0.27611809968948364\n",
      "In epoch 425, loss: 0.27658146619796753\n",
      "Epoch 426: Best model saved min loss 0.2761010527610779\n",
      "In epoch 430, loss: 0.2772097885608673\n",
      "In epoch 435, loss: 0.2762197256088257\n",
      "In epoch 440, loss: 0.2770172357559204\n",
      "In epoch 445, loss: 0.2793956398963928\n",
      "In epoch 450, loss: 0.2772558331489563\n",
      "Epoch 451: Best model saved min loss 0.2759261727333069\n",
      "In epoch 455, loss: 0.2766413688659668\n",
      "In epoch 460, loss: 0.2766934037208557\n",
      "In epoch 465, loss: 0.2766314446926117\n",
      "Epoch 467: Best model saved min loss 0.27566954493522644\n",
      "In epoch 470, loss: 0.27616095542907715\n",
      "In epoch 475, loss: 0.27639031410217285\n",
      "In epoch 480, loss: 0.27623310685157776\n",
      "In epoch 485, loss: 0.27660462260246277\n",
      "In epoch 490, loss: 0.27579039335250854\n",
      "In epoch 495, loss: 0.2758452594280243\n",
      "In epoch 500, loss: 0.27625614404678345\n",
      "Epoch 502: Best model saved min loss 0.27556249499320984\n",
      "Epoch 504: Best model saved min loss 0.27553790807724\n",
      "In epoch 505, loss: 0.27670425176620483\n",
      "Epoch 507: Best model saved min loss 0.27540525794029236\n",
      "In epoch 510, loss: 0.27638840675354004\n",
      "In epoch 515, loss: 0.27580469846725464\n",
      "In epoch 520, loss: 0.27643105387687683\n",
      "In epoch 525, loss: 0.27605918049812317\n",
      "In epoch 530, loss: 0.2769020199775696\n",
      "In epoch 535, loss: 0.2772420346736908\n",
      "In epoch 540, loss: 0.27596572041511536\n",
      "In epoch 545, loss: 0.2755933105945587\n",
      "In epoch 550, loss: 0.27825605869293213\n",
      "Epoch 552: Best model saved min loss 0.27537810802459717\n",
      "In epoch 555, loss: 0.277066707611084\n",
      "In epoch 560, loss: 0.2755059599876404\n",
      "In epoch 565, loss: 0.2758843004703522\n",
      "In epoch 570, loss: 0.27683016657829285\n",
      "Epoch 572: Best model saved min loss 0.2751075029373169\n",
      "In epoch 575, loss: 0.2759738564491272\n",
      "In epoch 580, loss: 0.27603718638420105\n",
      "In epoch 585, loss: 0.2753470242023468\n",
      "In epoch 590, loss: 0.2759247422218323\n",
      "In epoch 595, loss: 0.2777037024497986\n",
      "In epoch 600, loss: 0.2753676474094391\n",
      "In epoch 605, loss: 0.2751771807670593\n",
      "In epoch 610, loss: 0.27572980523109436\n",
      "In epoch 615, loss: 0.27618905901908875\n",
      "In epoch 620, loss: 0.27613353729248047\n",
      "In epoch 625, loss: 0.2756129503250122\n",
      "In epoch 630, loss: 0.27610939741134644\n",
      "In epoch 635, loss: 0.27555978298187256\n",
      "In epoch 640, loss: 0.27526143193244934\n",
      "In epoch 645, loss: 0.27537551522254944\n",
      "In epoch 650, loss: 0.27533313632011414\n",
      "Epoch 654: Best model saved min loss 0.2750425338745117\n",
      "In epoch 655, loss: 0.27752259373664856\n",
      "In epoch 660, loss: 0.2754606306552887\n",
      "In epoch 665, loss: 0.27495598793029785\n",
      "Epoch 665: Best model saved min loss 0.27495598793029785\n",
      "In epoch 670, loss: 0.27519121766090393\n",
      "In epoch 675, loss: 0.27573251724243164\n",
      "In epoch 680, loss: 0.27516114711761475\n",
      "In epoch 685, loss: 0.2756650745868683\n",
      "In epoch 690, loss: 0.27546003460884094\n",
      "In epoch 695, loss: 0.2748744785785675\n",
      "Epoch 695: Best model saved min loss 0.2748744785785675\n",
      "In epoch 700, loss: 0.27487605810165405\n",
      "In epoch 705, loss: 0.27595236897468567\n",
      "In epoch 710, loss: 0.27525660395622253\n",
      "Epoch 714: Best model saved min loss 0.27480098605155945\n",
      "In epoch 715, loss: 0.27529820799827576\n",
      "Epoch 716: Best model saved min loss 0.27458077669143677\n",
      "In epoch 720, loss: 0.2755706310272217\n",
      "In epoch 725, loss: 0.2749059498310089\n",
      "In epoch 730, loss: 0.27535104751586914\n",
      "In epoch 735, loss: 0.2755785882472992\n",
      "In epoch 740, loss: 0.2746860384941101\n",
      "In epoch 745, loss: 0.27491992712020874\n",
      "In epoch 750, loss: 0.27535581588745117\n",
      "In epoch 755, loss: 0.2751586437225342\n",
      "In epoch 760, loss: 0.27544498443603516\n",
      "In epoch 765, loss: 0.27484995126724243\n",
      "In epoch 770, loss: 0.2749217748641968\n",
      "Epoch 772: Best model saved min loss 0.2744773030281067\n",
      "Epoch 773: Best model saved min loss 0.27421972155570984\n",
      "In epoch 775, loss: 0.2745446562767029\n",
      "In epoch 780, loss: 0.2745051383972168\n",
      "Epoch 783: Best model saved min loss 0.2739282250404358\n",
      "In epoch 785, loss: 0.27572721242904663\n",
      "In epoch 790, loss: 0.2748431861400604\n",
      "In epoch 795, loss: 0.2744846045970917\n",
      "In epoch 800, loss: 0.27539488673210144\n",
      "Epoch 801: Best model saved min loss 0.27381253242492676\n",
      "Epoch 802: Best model saved min loss 0.2737311124801636\n",
      "In epoch 805, loss: 0.2746592164039612\n",
      "In epoch 810, loss: 0.273784875869751\n",
      "In epoch 815, loss: 0.27367737889289856\n",
      "Epoch 815: Best model saved min loss 0.27367737889289856\n",
      "In epoch 820, loss: 0.2745209336280823\n",
      "In epoch 825, loss: 0.27459463477134705\n",
      "In epoch 830, loss: 0.27504977583885193\n",
      "In epoch 835, loss: 0.275473028421402\n",
      "Epoch 836: Best model saved min loss 0.2735399901866913\n",
      "In epoch 840, loss: 0.275610089302063\n",
      "In epoch 845, loss: 0.2737881541252136\n",
      "In epoch 850, loss: 0.2761160135269165\n",
      "In epoch 855, loss: 0.27818921208381653\n",
      "In epoch 860, loss: 0.2752430737018585\n",
      "In epoch 865, loss: 0.27559778094291687\n",
      "In epoch 870, loss: 0.27577120065689087\n",
      "In epoch 875, loss: 0.2753154933452606\n",
      "In epoch 880, loss: 0.2747475504875183\n",
      "In epoch 885, loss: 0.27535974979400635\n",
      "In epoch 890, loss: 0.2754911184310913\n",
      "In epoch 895, loss: 0.27476757764816284\n",
      "In epoch 900, loss: 0.2756679356098175\n",
      "In epoch 905, loss: 0.27416735887527466\n",
      "In epoch 910, loss: 0.2734081447124481\n",
      "Epoch 910: Best model saved min loss 0.2734081447124481\n",
      "In epoch 915, loss: 0.27416616678237915\n",
      "In epoch 920, loss: 0.27315816283226013\n",
      "Epoch 920: Best model saved min loss 0.27315816283226013\n",
      "In epoch 925, loss: 0.2744677662849426\n",
      "In epoch 930, loss: 0.27385616302490234\n",
      "In epoch 935, loss: 0.2739919424057007\n",
      "In epoch 940, loss: 0.2745392322540283\n",
      "In epoch 945, loss: 0.27374598383903503\n",
      "In epoch 950, loss: 0.27442222833633423\n",
      "In epoch 955, loss: 0.27374371886253357\n",
      "Epoch 958: Best model saved min loss 0.27289411425590515\n",
      "In epoch 960, loss: 0.2732577323913574\n",
      "Epoch 961: Best model saved min loss 0.27282586693763733\n",
      "In epoch 965, loss: 0.27336612343788147\n",
      "Epoch 967: Best model saved min loss 0.27191829681396484\n",
      "In epoch 970, loss: 0.2736366093158722\n",
      "In epoch 975, loss: 0.27271032333374023\n",
      "In epoch 980, loss: 0.27277320623397827\n",
      "In epoch 985, loss: 0.27373915910720825\n",
      "In epoch 990, loss: 0.2803148329257965\n",
      "In epoch 995, loss: 0.27362188696861267\n",
      "Train AUC 0.9779668295027066\n",
      "Test AUC 0.9804645404065214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 7220.26it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 7987.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.6413160694399664\n",
      "Test recall@100 0.6659159794177769\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "temp = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_best_tuned_model',\n",
    "                                                                                                                                          n_epochs=1000,\n",
    "                                                                                                                                          image_included=False,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Inmage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umap conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node data shape : (10867, 139)\n",
      "Edges data shape : (20554, 2)\n",
      "Size of Input features : 100\n",
      "14388 6166\n",
      "In epoch 0, loss: 362.3859558105469\n",
      "Epoch 0: Best model saved min loss 362.3859558105469\n",
      "Epoch 1: Best model saved min loss 49.30842590332031\n",
      "Epoch 2: Best model saved min loss 2.5294275283813477\n",
      "Epoch 3: Best model saved min loss 0.7108553647994995\n",
      "Epoch 4: Best model saved min loss 0.6415542960166931\n",
      "In epoch 5, loss: 0.6258664131164551\n",
      "Epoch 5: Best model saved min loss 0.6258664131164551\n",
      "Epoch 6: Best model saved min loss 0.605273425579071\n",
      "Epoch 7: Best model saved min loss 0.5787621736526489\n",
      "Epoch 8: Best model saved min loss 0.5468220710754395\n",
      "Epoch 9: Best model saved min loss 0.5087475180625916\n",
      "In epoch 10, loss: 0.4648645222187042\n",
      "Epoch 10: Best model saved min loss 0.4648645222187042\n",
      "Epoch 11: Best model saved min loss 0.41895592212677\n",
      "Epoch 12: Best model saved min loss 0.3791041374206543\n",
      "Epoch 13: Best model saved min loss 0.3518766760826111\n",
      "Epoch 14: Best model saved min loss 0.33786076307296753\n",
      "In epoch 15, loss: 0.3341669738292694\n",
      "Epoch 15: Best model saved min loss 0.3341669738292694\n",
      "In epoch 20, loss: 0.35765698552131653\n",
      "In epoch 25, loss: 0.34105774760246277\n",
      "Epoch 27: Best model saved min loss 0.3295736610889435\n",
      "Epoch 28: Best model saved min loss 0.3247816860675812\n",
      "Epoch 29: Best model saved min loss 0.3212684094905853\n",
      "In epoch 30, loss: 0.3192368447780609\n",
      "Epoch 30: Best model saved min loss 0.3192368447780609\n",
      "Epoch 31: Best model saved min loss 0.3181837797164917\n",
      "Epoch 32: Best model saved min loss 0.3171146512031555\n",
      "Epoch 33: Best model saved min loss 0.3152399957180023\n",
      "Epoch 34: Best model saved min loss 0.31246769428253174\n",
      "In epoch 35, loss: 0.3094119727611542\n",
      "Epoch 35: Best model saved min loss 0.3094119727611542\n",
      "Epoch 36: Best model saved min loss 0.30664917826652527\n",
      "Epoch 37: Best model saved min loss 0.3042336404323578\n",
      "Epoch 38: Best model saved min loss 0.302015483379364\n",
      "Epoch 39: Best model saved min loss 0.29990899562835693\n",
      "In epoch 40, loss: 0.2979133725166321\n",
      "Epoch 40: Best model saved min loss 0.2979133725166321\n",
      "Epoch 41: Best model saved min loss 0.2960819900035858\n",
      "Epoch 42: Best model saved min loss 0.29451310634613037\n",
      "Epoch 43: Best model saved min loss 0.2933388948440552\n",
      "Epoch 44: Best model saved min loss 0.29228103160858154\n",
      "In epoch 45, loss: 0.29084324836730957\n",
      "Epoch 45: Best model saved min loss 0.29084324836730957\n",
      "Epoch 46: Best model saved min loss 0.28975582122802734\n",
      "Epoch 47: Best model saved min loss 0.28902706503868103\n",
      "Epoch 48: Best model saved min loss 0.28844374418258667\n",
      "Epoch 49: Best model saved min loss 0.28787127137184143\n",
      "In epoch 50, loss: 0.28724831342697144\n",
      "Epoch 50: Best model saved min loss 0.28724831342697144\n",
      "Epoch 51: Best model saved min loss 0.2865847945213318\n",
      "Epoch 52: Best model saved min loss 0.2860105037689209\n",
      "Epoch 53: Best model saved min loss 0.2857932448387146\n",
      "Epoch 54: Best model saved min loss 0.28524836897850037\n",
      "In epoch 55, loss: 0.2847464680671692\n",
      "Epoch 55: Best model saved min loss 0.2847464680671692\n",
      "Epoch 56: Best model saved min loss 0.2844638228416443\n",
      "Epoch 57: Best model saved min loss 0.28414177894592285\n",
      "Epoch 58: Best model saved min loss 0.2837121784687042\n",
      "Epoch 59: Best model saved min loss 0.2832828164100647\n",
      "In epoch 60, loss: 0.2830679714679718\n",
      "Epoch 60: Best model saved min loss 0.2830679714679718\n",
      "Epoch 61: Best model saved min loss 0.2827521860599518\n",
      "Epoch 62: Best model saved min loss 0.28236836194992065\n",
      "Epoch 63: Best model saved min loss 0.28215155005455017\n",
      "Epoch 64: Best model saved min loss 0.28190553188323975\n",
      "In epoch 65, loss: 0.2815985083580017\n",
      "Epoch 65: Best model saved min loss 0.2815985083580017\n",
      "Epoch 66: Best model saved min loss 0.2813989222049713\n",
      "Epoch 67: Best model saved min loss 0.28124022483825684\n",
      "Epoch 68: Best model saved min loss 0.2809789180755615\n",
      "Epoch 69: Best model saved min loss 0.2808403968811035\n",
      "In epoch 70, loss: 0.2806931138038635\n",
      "Epoch 70: Best model saved min loss 0.2806931138038635\n",
      "Epoch 71: Best model saved min loss 0.28049585223197937\n",
      "Epoch 72: Best model saved min loss 0.28036609292030334\n",
      "Epoch 73: Best model saved min loss 0.28022950887680054\n",
      "Epoch 74: Best model saved min loss 0.28004443645477295\n",
      "In epoch 75, loss: 0.2799176275730133\n",
      "Epoch 75: Best model saved min loss 0.2799176275730133\n",
      "Epoch 76: Best model saved min loss 0.2797718644142151\n",
      "Epoch 77: Best model saved min loss 0.2796023488044739\n",
      "Epoch 78: Best model saved min loss 0.2794766128063202\n",
      "Epoch 79: Best model saved min loss 0.27933594584465027\n",
      "In epoch 80, loss: 0.27918606996536255\n",
      "Epoch 80: Best model saved min loss 0.27918606996536255\n",
      "Epoch 81: Best model saved min loss 0.279073566198349\n",
      "Epoch 82: Best model saved min loss 0.27894625067710876\n",
      "Epoch 83: Best model saved min loss 0.27882739901542664\n",
      "Epoch 84: Best model saved min loss 0.2787381410598755\n",
      "In epoch 85, loss: 0.2786245346069336\n",
      "Epoch 85: Best model saved min loss 0.2786245346069336\n",
      "Epoch 86: Best model saved min loss 0.2785440683364868\n",
      "Epoch 87: Best model saved min loss 0.2784577012062073\n",
      "Epoch 88: Best model saved min loss 0.27838557958602905\n",
      "Epoch 89: Best model saved min loss 0.2783200740814209\n",
      "In epoch 90, loss: 0.2782583236694336\n",
      "Epoch 90: Best model saved min loss 0.2782583236694336\n",
      "Epoch 91: Best model saved min loss 0.27820321917533875\n",
      "Epoch 92: Best model saved min loss 0.27815675735473633\n",
      "Epoch 93: Best model saved min loss 0.2780994772911072\n",
      "Epoch 94: Best model saved min loss 0.27806204557418823\n",
      "In epoch 95, loss: 0.2780078649520874\n",
      "Epoch 95: Best model saved min loss 0.2780078649520874\n",
      "Epoch 96: Best model saved min loss 0.277958482503891\n",
      "Epoch 97: Best model saved min loss 0.27791911363601685\n",
      "Epoch 98: Best model saved min loss 0.27786970138549805\n",
      "Epoch 99: Best model saved min loss 0.27781710028648376\n",
      "Train AUC 0.9775345657179246\n",
      "Test AUC 0.9805843734734829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 7392.85it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 8071.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.667577469007049\n",
      "Test recall@100 0.675622048354127\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_only_image_features_umap',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=True,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umap and bidirectional graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node data shape : (10867, 139)\n",
      "Edges data shape : (20554, 2)\n",
      "Size of Input features : 100\n",
      "##########################\n",
      "Converting to biderctional Graph\n",
      "##########################\n",
      "27998 11999\n",
      "In epoch 0, loss: 372.73919677734375\n",
      "Epoch 0: Best model saved min loss 372.73919677734375\n",
      "Epoch 1: Best model saved min loss 39.797733306884766\n",
      "Epoch 2: Best model saved min loss 1.552703857421875\n",
      "Epoch 3: Best model saved min loss 0.5510805249214172\n",
      "Epoch 4: Best model saved min loss 0.48610302805900574\n",
      "In epoch 5, loss: 0.4377387464046478\n",
      "Epoch 5: Best model saved min loss 0.4377387464046478\n",
      "Epoch 6: Best model saved min loss 0.39815646409988403\n",
      "Epoch 7: Best model saved min loss 0.3846866488456726\n",
      "In epoch 10, loss: 0.42446786165237427\n",
      "Epoch 14: Best model saved min loss 0.3813266158103943\n",
      "In epoch 15, loss: 0.3676895201206207\n",
      "Epoch 15: Best model saved min loss 0.3676895201206207\n",
      "Epoch 16: Best model saved min loss 0.35945412516593933\n",
      "Epoch 17: Best model saved min loss 0.35641881823539734\n",
      "Epoch 18: Best model saved min loss 0.3563685119152069\n",
      "Epoch 19: Best model saved min loss 0.35610154271125793\n",
      "In epoch 20, loss: 0.3528800904750824\n",
      "Epoch 20: Best model saved min loss 0.3528800904750824\n",
      "Epoch 21: Best model saved min loss 0.3458256125450134\n",
      "Epoch 22: Best model saved min loss 0.33635058999061584\n",
      "Epoch 23: Best model saved min loss 0.32690224051475525\n",
      "Epoch 24: Best model saved min loss 0.31929779052734375\n",
      "In epoch 25, loss: 0.3141639530658722\n",
      "Epoch 25: Best model saved min loss 0.3141639530658722\n",
      "Epoch 26: Best model saved min loss 0.31108567118644714\n",
      "Epoch 27: Best model saved min loss 0.30894142389297485\n",
      "Epoch 28: Best model saved min loss 0.3064396381378174\n",
      "Epoch 29: Best model saved min loss 0.30272021889686584\n",
      "In epoch 30, loss: 0.2977486848831177\n",
      "Epoch 30: Best model saved min loss 0.2977486848831177\n",
      "Epoch 31: Best model saved min loss 0.29235944151878357\n",
      "Epoch 32: Best model saved min loss 0.28796684741973877\n",
      "Epoch 33: Best model saved min loss 0.28603464365005493\n",
      "In epoch 35, loss: 0.286954790353775\n",
      "Epoch 36: Best model saved min loss 0.2821089029312134\n",
      "Epoch 37: Best model saved min loss 0.2791002094745636\n",
      "In epoch 40, loss: 0.2796339988708496\n",
      "Epoch 41: Best model saved min loss 0.2777387201786041\n",
      "Epoch 42: Best model saved min loss 0.2753250002861023\n",
      "Epoch 43: Best model saved min loss 0.27430927753448486\n",
      "In epoch 45, loss: 0.2749280333518982\n",
      "Epoch 46: Best model saved min loss 0.2727837562561035\n",
      "Epoch 47: Best model saved min loss 0.2720736861228943\n",
      "In epoch 50, loss: 0.2715829014778137\n",
      "Epoch 50: Best model saved min loss 0.2715829014778137\n",
      "Epoch 51: Best model saved min loss 0.2705000936985016\n",
      "Epoch 52: Best model saved min loss 0.26999402046203613\n",
      "In epoch 55, loss: 0.2693116068840027\n",
      "Epoch 55: Best model saved min loss 0.2693116068840027\n",
      "Epoch 56: Best model saved min loss 0.26864945888519287\n",
      "Epoch 57: Best model saved min loss 0.2685176134109497\n",
      "Epoch 58: Best model saved min loss 0.26850953698158264\n",
      "Epoch 59: Best model saved min loss 0.2682008445262909\n",
      "In epoch 60, loss: 0.2677110731601715\n",
      "Epoch 60: Best model saved min loss 0.2677110731601715\n",
      "Epoch 62: Best model saved min loss 0.26749739050865173\n",
      "Epoch 63: Best model saved min loss 0.26715731620788574\n",
      "Epoch 64: Best model saved min loss 0.266960471868515\n",
      "In epoch 65, loss: 0.26684385538101196\n",
      "Epoch 65: Best model saved min loss 0.26684385538101196\n",
      "Epoch 66: Best model saved min loss 0.26678115129470825\n",
      "Epoch 67: Best model saved min loss 0.2666977643966675\n",
      "Epoch 68: Best model saved min loss 0.26656726002693176\n",
      "Epoch 69: Best model saved min loss 0.266438752412796\n",
      "In epoch 70, loss: 0.2663440406322479\n",
      "Epoch 70: Best model saved min loss 0.2663440406322479\n",
      "Epoch 71: Best model saved min loss 0.2662416994571686\n",
      "Epoch 72: Best model saved min loss 0.2661011815071106\n",
      "Epoch 73: Best model saved min loss 0.2659611999988556\n",
      "Epoch 74: Best model saved min loss 0.26584872603416443\n",
      "In epoch 75, loss: 0.265735387802124\n",
      "Epoch 75: Best model saved min loss 0.265735387802124\n",
      "Epoch 76: Best model saved min loss 0.26560306549072266\n",
      "Epoch 77: Best model saved min loss 0.26547878980636597\n",
      "Epoch 78: Best model saved min loss 0.26538267731666565\n",
      "Epoch 79: Best model saved min loss 0.26529446244239807\n",
      "In epoch 80, loss: 0.2652015686035156\n",
      "Epoch 80: Best model saved min loss 0.2652015686035156\n",
      "Epoch 81: Best model saved min loss 0.26512372493743896\n",
      "Epoch 82: Best model saved min loss 0.26506543159484863\n",
      "Epoch 83: Best model saved min loss 0.2649986445903778\n",
      "Epoch 84: Best model saved min loss 0.26490601897239685\n",
      "In epoch 85, loss: 0.26480409502983093\n",
      "Epoch 85: Best model saved min loss 0.26480409502983093\n",
      "Epoch 86: Best model saved min loss 0.2647131085395813\n",
      "Epoch 87: Best model saved min loss 0.2646307945251465\n",
      "Epoch 88: Best model saved min loss 0.2645503878593445\n",
      "Epoch 89: Best model saved min loss 0.2644769251346588\n",
      "In epoch 90, loss: 0.26441073417663574\n",
      "Epoch 90: Best model saved min loss 0.26441073417663574\n",
      "Epoch 91: Best model saved min loss 0.26434215903282166\n",
      "Epoch 92: Best model saved min loss 0.26426953077316284\n",
      "Epoch 93: Best model saved min loss 0.2641986608505249\n",
      "Epoch 94: Best model saved min loss 0.2641274333000183\n",
      "In epoch 95, loss: 0.26405149698257446\n",
      "Epoch 95: Best model saved min loss 0.26405149698257446\n",
      "Epoch 96: Best model saved min loss 0.26397547125816345\n",
      "Epoch 97: Best model saved min loss 0.26390284299850464\n",
      "Epoch 98: Best model saved min loss 0.2638315260410309\n",
      "Epoch 99: Best model saved min loss 0.2637641727924347\n",
      "In epoch 100, loss: 0.26370397210121155\n",
      "Epoch 100: Best model saved min loss 0.26370397210121155\n",
      "Epoch 101: Best model saved min loss 0.2636432349681854\n",
      "Epoch 102: Best model saved min loss 0.2635771930217743\n",
      "Epoch 103: Best model saved min loss 0.2635119557380676\n",
      "Epoch 104: Best model saved min loss 0.26344749331474304\n",
      "In epoch 105, loss: 0.26338496804237366\n",
      "Epoch 105: Best model saved min loss 0.26338496804237366\n",
      "Epoch 106: Best model saved min loss 0.2633282542228699\n",
      "Epoch 107: Best model saved min loss 0.263272762298584\n",
      "Epoch 108: Best model saved min loss 0.26321518421173096\n",
      "Epoch 109: Best model saved min loss 0.26315900683403015\n",
      "In epoch 110, loss: 0.26310282945632935\n",
      "Epoch 110: Best model saved min loss 0.26310282945632935\n",
      "Epoch 111: Best model saved min loss 0.2630465626716614\n",
      "Epoch 112: Best model saved min loss 0.2629956007003784\n",
      "Epoch 113: Best model saved min loss 0.2629459798336029\n",
      "Epoch 114: Best model saved min loss 0.26289376616477966\n",
      "In epoch 115, loss: 0.26284369826316833\n",
      "Epoch 115: Best model saved min loss 0.26284369826316833\n",
      "Epoch 116: Best model saved min loss 0.26279258728027344\n",
      "Epoch 117: Best model saved min loss 0.2627438008785248\n",
      "Epoch 118: Best model saved min loss 0.26269808411598206\n",
      "Epoch 119: Best model saved min loss 0.2626498341560364\n",
      "In epoch 120, loss: 0.2626030147075653\n",
      "Epoch 120: Best model saved min loss 0.2626030147075653\n",
      "Epoch 121: Best model saved min loss 0.26255714893341064\n",
      "Epoch 122: Best model saved min loss 0.2625128924846649\n",
      "Epoch 123: Best model saved min loss 0.2624695301055908\n",
      "Epoch 124: Best model saved min loss 0.2624244689941406\n",
      "In epoch 125, loss: 0.262382447719574\n",
      "Epoch 125: Best model saved min loss 0.262382447719574\n",
      "Epoch 126: Best model saved min loss 0.2623402774333954\n",
      "Epoch 127: Best model saved min loss 0.2622997462749481\n",
      "Epoch 128: Best model saved min loss 0.2622581720352173\n",
      "Epoch 129: Best model saved min loss 0.2622186839580536\n",
      "In epoch 130, loss: 0.26217982172966003\n",
      "Epoch 130: Best model saved min loss 0.26217982172966003\n",
      "Epoch 131: Best model saved min loss 0.2621416747570038\n",
      "Epoch 132: Best model saved min loss 0.2621031105518341\n",
      "Epoch 133: Best model saved min loss 0.26206666231155396\n",
      "Epoch 134: Best model saved min loss 0.2620301842689514\n",
      "In epoch 135, loss: 0.2619943916797638\n",
      "Epoch 135: Best model saved min loss 0.2619943916797638\n",
      "Epoch 136: Best model saved min loss 0.26195889711380005\n",
      "Epoch 137: Best model saved min loss 0.26192471385002136\n",
      "Epoch 138: Best model saved min loss 0.2618907690048218\n",
      "Epoch 139: Best model saved min loss 0.2618568539619446\n",
      "In epoch 140, loss: 0.26182422041893005\n",
      "Epoch 140: Best model saved min loss 0.26182422041893005\n",
      "Epoch 141: Best model saved min loss 0.2617918848991394\n",
      "Epoch 142: Best model saved min loss 0.26175957918167114\n",
      "Epoch 143: Best model saved min loss 0.2617282569408417\n",
      "Epoch 144: Best model saved min loss 0.26169753074645996\n",
      "In epoch 145, loss: 0.2616669833660126\n",
      "Epoch 145: Best model saved min loss 0.2616669833660126\n",
      "Epoch 146: Best model saved min loss 0.26163703203201294\n",
      "Epoch 147: Best model saved min loss 0.2616075277328491\n",
      "Epoch 148: Best model saved min loss 0.26157817244529724\n",
      "Epoch 149: Best model saved min loss 0.26154962182044983\n",
      "In epoch 150, loss: 0.261522114276886\n",
      "Epoch 150: Best model saved min loss 0.261522114276886\n",
      "Epoch 151: Best model saved min loss 0.26149889826774597\n",
      "Epoch 152: Best model saved min loss 0.26149213314056396\n",
      "In epoch 155, loss: 0.2615644931793213\n",
      "Epoch 156: Best model saved min loss 0.2614136040210724\n",
      "In epoch 160, loss: 0.26162976026535034\n",
      "Epoch 162: Best model saved min loss 0.26139968633651733\n",
      "In epoch 165, loss: 0.2632938027381897\n",
      "In epoch 170, loss: 0.2632070481777191\n",
      "In epoch 175, loss: 0.2627941370010376\n",
      "In epoch 180, loss: 0.26158201694488525\n",
      "In epoch 185, loss: 0.26137396693229675\n",
      "Epoch 185: Best model saved min loss 0.26137396693229675\n",
      "Epoch 187: Best model saved min loss 0.26130032539367676\n",
      "Epoch 189: Best model saved min loss 0.2612350881099701\n",
      "In epoch 190, loss: 0.26144540309906006\n",
      "Epoch 193: Best model saved min loss 0.26120904088020325\n",
      "Epoch 194: Best model saved min loss 0.26117318868637085\n",
      "In epoch 195, loss: 0.26120737195014954\n",
      "Epoch 196: Best model saved min loss 0.2610766291618347\n",
      "Epoch 198: Best model saved min loss 0.26099854707717896\n",
      "In epoch 200, loss: 0.2609628438949585\n",
      "Epoch 200: Best model saved min loss 0.2609628438949585\n",
      "Epoch 202: Best model saved min loss 0.26090604066848755\n",
      "Epoch 204: Best model saved min loss 0.26087236404418945\n",
      "In epoch 205, loss: 0.2609228491783142\n",
      "Epoch 206: Best model saved min loss 0.26083606481552124\n",
      "Epoch 208: Best model saved min loss 0.26079437136650085\n",
      "In epoch 210, loss: 0.2607489228248596\n",
      "Epoch 210: Best model saved min loss 0.2607489228248596\n",
      "Epoch 212: Best model saved min loss 0.26070886850357056\n",
      "Epoch 214: Best model saved min loss 0.26067182421684265\n",
      "In epoch 215, loss: 0.2606862187385559\n",
      "Epoch 216: Best model saved min loss 0.2606356739997864\n",
      "Epoch 218: Best model saved min loss 0.2606015205383301\n",
      "Epoch 219: Best model saved min loss 0.2606010437011719\n",
      "In epoch 220, loss: 0.26057055592536926\n",
      "Epoch 220: Best model saved min loss 0.26057055592536926\n",
      "Epoch 221: Best model saved min loss 0.26056039333343506\n",
      "Epoch 222: Best model saved min loss 0.2605415880680084\n",
      "Epoch 223: Best model saved min loss 0.26052001118659973\n",
      "Epoch 224: Best model saved min loss 0.26051095128059387\n",
      "In epoch 225, loss: 0.2604830265045166\n",
      "Epoch 225: Best model saved min loss 0.2604830265045166\n",
      "Epoch 226: Best model saved min loss 0.26047831773757935\n",
      "Epoch 227: Best model saved min loss 0.2604517936706543\n",
      "Epoch 228: Best model saved min loss 0.2604440748691559\n",
      "Epoch 229: Best model saved min loss 0.2604253888130188\n",
      "In epoch 230, loss: 0.2604082524776459\n",
      "Epoch 230: Best model saved min loss 0.2604082524776459\n",
      "Epoch 231: Best model saved min loss 0.2603979706764221\n",
      "Epoch 232: Best model saved min loss 0.26037606596946716\n",
      "Epoch 233: Best model saved min loss 0.260366827249527\n",
      "Epoch 234: Best model saved min loss 0.2603487968444824\n",
      "In epoch 235, loss: 0.2603341042995453\n",
      "Epoch 235: Best model saved min loss 0.2603341042995453\n",
      "Epoch 236: Best model saved min loss 0.2603226900100708\n",
      "Epoch 237: Best model saved min loss 0.26030421257019043\n",
      "Epoch 238: Best model saved min loss 0.2602931261062622\n",
      "Epoch 239: Best model saved min loss 0.2602781057357788\n",
      "In epoch 240, loss: 0.2602625787258148\n",
      "Epoch 240: Best model saved min loss 0.2602625787258148\n",
      "Epoch 241: Best model saved min loss 0.2602517604827881\n",
      "Epoch 242: Best model saved min loss 0.2602359354496002\n",
      "Epoch 243: Best model saved min loss 0.2602223753929138\n",
      "Epoch 244: Best model saved min loss 0.2602105438709259\n",
      "In epoch 245, loss: 0.26019513607025146\n",
      "Epoch 245: Best model saved min loss 0.26019513607025146\n",
      "Epoch 246: Best model saved min loss 0.26018235087394714\n",
      "Epoch 247: Best model saved min loss 0.26017025113105774\n",
      "Epoch 248: Best model saved min loss 0.26015570759773254\n",
      "Epoch 249: Best model saved min loss 0.26014313101768494\n",
      "In epoch 250, loss: 0.2601311206817627\n",
      "Epoch 250: Best model saved min loss 0.2601311206817627\n",
      "Epoch 251: Best model saved min loss 0.26011723279953003\n",
      "Epoch 252: Best model saved min loss 0.26010453701019287\n",
      "Epoch 253: Best model saved min loss 0.2600927948951721\n",
      "Epoch 254: Best model saved min loss 0.26007968187332153\n",
      "In epoch 255, loss: 0.26006680727005005\n",
      "Epoch 255: Best model saved min loss 0.26006680727005005\n",
      "Epoch 256: Best model saved min loss 0.2600550949573517\n",
      "Epoch 257: Best model saved min loss 0.2600429058074951\n",
      "Epoch 258: Best model saved min loss 0.2600300908088684\n",
      "Epoch 259: Best model saved min loss 0.2600180506706238\n",
      "In epoch 260, loss: 0.26000654697418213\n",
      "Epoch 260: Best model saved min loss 0.26000654697418213\n",
      "Epoch 261: Best model saved min loss 0.2599945068359375\n",
      "Epoch 262: Best model saved min loss 0.25998222827911377\n",
      "Epoch 263: Best model saved min loss 0.2599705159664154\n",
      "Epoch 264: Best model saved min loss 0.2599591314792633\n",
      "In epoch 265, loss: 0.2599475383758545\n",
      "Epoch 265: Best model saved min loss 0.2599475383758545\n",
      "Epoch 266: Best model saved min loss 0.25993576645851135\n",
      "Epoch 267: Best model saved min loss 0.25992411375045776\n",
      "Epoch 268: Best model saved min loss 0.2599128782749176\n",
      "Epoch 269: Best model saved min loss 0.25990182161331177\n",
      "In epoch 270, loss: 0.25989070534706116\n",
      "Epoch 270: Best model saved min loss 0.25989070534706116\n",
      "Epoch 271: Best model saved min loss 0.2598794996738434\n",
      "Epoch 272: Best model saved min loss 0.259868323802948\n",
      "Epoch 273: Best model saved min loss 0.25985732674598694\n",
      "Epoch 274: Best model saved min loss 0.2598464787006378\n",
      "In epoch 275, loss: 0.259835809469223\n",
      "Epoch 275: Best model saved min loss 0.259835809469223\n",
      "Epoch 276: Best model saved min loss 0.25982528924942017\n",
      "Epoch 277: Best model saved min loss 0.2598148584365845\n",
      "Epoch 278: Best model saved min loss 0.2598045766353607\n",
      "Epoch 279: Best model saved min loss 0.2597945034503937\n",
      "In epoch 280, loss: 0.25978466868400574\n",
      "Epoch 280: Best model saved min loss 0.25978466868400574\n",
      "Epoch 281: Best model saved min loss 0.2597754895687103\n",
      "Epoch 282: Best model saved min loss 0.25976741313934326\n",
      "Epoch 283: Best model saved min loss 0.25976255536079407\n",
      "In epoch 285, loss: 0.25978776812553406\n",
      "In epoch 290, loss: 0.2604409456253052\n",
      "Epoch 292: Best model saved min loss 0.25974923372268677\n",
      "In epoch 295, loss: 0.26048704981803894\n",
      "In epoch 300, loss: 0.2600786089897156\n",
      "Epoch 302: Best model saved min loss 0.2596394419670105\n",
      "In epoch 305, loss: 0.2600173354148865\n",
      "Epoch 307: Best model saved min loss 0.2596164643764496\n",
      "In epoch 310, loss: 0.2596837878227234\n",
      "Epoch 311: Best model saved min loss 0.2595650553703308\n",
      "In epoch 315, loss: 0.2598138451576233\n",
      "Epoch 317: Best model saved min loss 0.25952455401420593\n",
      "In epoch 320, loss: 0.26021885871887207\n",
      "In epoch 325, loss: 0.25980913639068604\n",
      "In epoch 330, loss: 0.2594873309135437\n",
      "Epoch 330: Best model saved min loss 0.2594873309135437\n",
      "In epoch 335, loss: 0.259481281042099\n",
      "Epoch 335: Best model saved min loss 0.259481281042099\n",
      "In epoch 340, loss: 0.25944983959198\n",
      "Epoch 340: Best model saved min loss 0.25944983959198\n",
      "Epoch 341: Best model saved min loss 0.25942325592041016\n",
      "In epoch 345, loss: 0.2594138979911804\n",
      "Epoch 345: Best model saved min loss 0.2594138979911804\n",
      "Epoch 346: Best model saved min loss 0.259389728307724\n",
      "In epoch 350, loss: 0.25957199931144714\n",
      "Epoch 353: Best model saved min loss 0.25938042998313904\n",
      "Epoch 354: Best model saved min loss 0.2593485414981842\n",
      "In epoch 355, loss: 0.2594049870967865\n",
      "In epoch 360, loss: 0.26008403301239014\n",
      "In epoch 365, loss: 0.25942927598953247\n",
      "Epoch 366: Best model saved min loss 0.25930771231651306\n",
      "In epoch 370, loss: 0.25928547978401184\n",
      "Epoch 370: Best model saved min loss 0.25928547978401184\n",
      "In epoch 375, loss: 0.259365051984787\n",
      "Epoch 376: Best model saved min loss 0.2592579126358032\n",
      "In epoch 380, loss: 0.25940898060798645\n",
      "Epoch 382: Best model saved min loss 0.25924479961395264\n",
      "Epoch 383: Best model saved min loss 0.2592087388038635\n",
      "Epoch 384: Best model saved min loss 0.25920727849006653\n",
      "In epoch 385, loss: 0.2592301070690155\n",
      "In epoch 390, loss: 0.25923699140548706\n",
      "Epoch 391: Best model saved min loss 0.259205162525177\n",
      "Epoch 392: Best model saved min loss 0.2591691315174103\n",
      "Epoch 393: Best model saved min loss 0.25915247201919556\n",
      "Epoch 394: Best model saved min loss 0.2591465711593628\n",
      "In epoch 395, loss: 0.259145587682724\n",
      "Epoch 395: Best model saved min loss 0.259145587682724\n",
      "In epoch 400, loss: 0.25942450761795044\n",
      "In epoch 405, loss: 0.2592008709907532\n",
      "Epoch 406: Best model saved min loss 0.25914284586906433\n",
      "In epoch 410, loss: 0.25969281792640686\n",
      "In epoch 415, loss: 0.2592863142490387\n",
      "Epoch 416: Best model saved min loss 0.25906994938850403\n",
      "In epoch 420, loss: 0.25925272703170776\n",
      "In epoch 425, loss: 0.25919216871261597\n",
      "Epoch 427: Best model saved min loss 0.2590164840221405\n",
      "Epoch 428: Best model saved min loss 0.25900721549987793\n",
      "In epoch 430, loss: 0.2590562701225281\n",
      "Epoch 433: Best model saved min loss 0.25899821519851685\n",
      "Epoch 434: Best model saved min loss 0.25897249579429626\n",
      "In epoch 435, loss: 0.25895920395851135\n",
      "Epoch 435: Best model saved min loss 0.25895920395851135\n",
      "Epoch 436: Best model saved min loss 0.2589535415172577\n",
      "Epoch 437: Best model saved min loss 0.25895291566848755\n",
      "In epoch 440, loss: 0.2589801549911499\n",
      "In epoch 445, loss: 0.2590431869029999\n",
      "In epoch 450, loss: 0.25918084383010864\n",
      "Epoch 453: Best model saved min loss 0.25892874598503113\n",
      "Epoch 454: Best model saved min loss 0.2588832974433899\n",
      "In epoch 455, loss: 0.258859783411026\n",
      "Epoch 455: Best model saved min loss 0.258859783411026\n",
      "Epoch 456: Best model saved min loss 0.2588481307029724\n",
      "Epoch 457: Best model saved min loss 0.25883999466896057\n",
      "Epoch 458: Best model saved min loss 0.2588379383087158\n",
      "In epoch 460, loss: 0.25884780287742615\n",
      "In epoch 465, loss: 0.26122739911079407\n",
      "In epoch 470, loss: 0.2616496682167053\n",
      "In epoch 475, loss: 0.25939831137657166\n",
      "Epoch 476: Best model saved min loss 0.2588329017162323\n",
      "In epoch 480, loss: 0.2587713897228241\n",
      "Epoch 480: Best model saved min loss 0.2587713897228241\n",
      "In epoch 485, loss: 0.2587658762931824\n",
      "Epoch 485: Best model saved min loss 0.2587658762931824\n",
      "Epoch 489: Best model saved min loss 0.2587182819843292\n",
      "In epoch 490, loss: 0.25878363847732544\n",
      "Epoch 494: Best model saved min loss 0.25868478417396545\n",
      "In epoch 495, loss: 0.2587188482284546\n",
      "Epoch 499: Best model saved min loss 0.25866252183914185\n",
      "Train AUC 0.9582387548604299\n",
      "Test AUC 0.8959261724459205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 8478.15it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 8201.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.6110382950649625\n",
      "Test recall@100 0.5978765462443362\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_only_image_features_umap_bidirectional',\n",
    "                                                                                                                                          n_epochs=500,\n",
    "                                                                                                                                          image_included=True,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=True,use_bidirectional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Image Data but without dimensionality reduction ( UMAP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14388 6166\n",
      "In epoch 0, loss: 135.67117309570312\n",
      "Epoch 0: Best model saved min loss 135.67117309570312\n",
      "Epoch 1: Best model saved min loss 64.02444458007812\n",
      "Epoch 2: Best model saved min loss 7.818566799163818\n",
      "Epoch 3: Best model saved min loss 4.381886005401611\n",
      "In epoch 5, loss: 3.6987273693084717\n",
      "Epoch 5: Best model saved min loss 3.6987273693084717\n",
      "Epoch 6: Best model saved min loss 3.201510429382324\n",
      "Epoch 7: Best model saved min loss 1.0914448499679565\n",
      "Epoch 9: Best model saved min loss 1.0666038990020752\n",
      "In epoch 10, loss: 0.7249850034713745\n",
      "Epoch 10: Best model saved min loss 0.7249850034713745\n",
      "Epoch 11: Best model saved min loss 0.45038852095603943\n",
      "Epoch 13: Best model saved min loss 0.3838786482810974\n",
      "In epoch 15, loss: 0.3950403928756714\n",
      "Epoch 17: Best model saved min loss 0.38094812631607056\n",
      "Epoch 18: Best model saved min loss 0.3762642443180084\n",
      "Epoch 19: Best model saved min loss 0.3620353043079376\n",
      "In epoch 20, loss: 0.3528943657875061\n",
      "Epoch 20: Best model saved min loss 0.3528943657875061\n",
      "In epoch 25, loss: 0.34706225991249084\n",
      "Epoch 25: Best model saved min loss 0.34706225991249084\n",
      "Epoch 26: Best model saved min loss 0.3461330235004425\n",
      "Epoch 28: Best model saved min loss 0.34101423621177673\n",
      "In epoch 30, loss: 0.33228394389152527\n",
      "Epoch 30: Best model saved min loss 0.33228394389152527\n",
      "Epoch 32: Best model saved min loss 0.3244154751300812\n",
      "Epoch 34: Best model saved min loss 0.32210293412208557\n",
      "In epoch 35, loss: 0.31530478596687317\n",
      "Epoch 35: Best model saved min loss 0.31530478596687317\n",
      "Epoch 38: Best model saved min loss 0.3133430778980255\n",
      "Epoch 39: Best model saved min loss 0.3110186755657196\n",
      "In epoch 40, loss: 0.31280916929244995\n",
      "Epoch 42: Best model saved min loss 0.3080627918243408\n",
      "Epoch 43: Best model saved min loss 0.30555546283721924\n",
      "Epoch 44: Best model saved min loss 0.30396756529808044\n",
      "In epoch 45, loss: 0.3007982075214386\n",
      "Epoch 45: Best model saved min loss 0.3007982075214386\n",
      "Epoch 47: Best model saved min loss 0.2976128160953522\n",
      "Epoch 49: Best model saved min loss 0.29600703716278076\n",
      "In epoch 50, loss: 0.29604265093803406\n",
      "Epoch 51: Best model saved min loss 0.2928798794746399\n",
      "Epoch 52: Best model saved min loss 0.29206591844558716\n",
      "Epoch 54: Best model saved min loss 0.2919602394104004\n",
      "In epoch 55, loss: 0.29192841053009033\n",
      "Epoch 55: Best model saved min loss 0.29192841053009033\n",
      "Epoch 56: Best model saved min loss 0.28928300738334656\n",
      "Epoch 59: Best model saved min loss 0.2888564467430115\n",
      "In epoch 60, loss: 0.2898663878440857\n",
      "Epoch 62: Best model saved min loss 0.2884235084056854\n",
      "In epoch 65, loss: 0.28926947712898254\n",
      "Epoch 66: Best model saved min loss 0.2875185012817383\n",
      "Epoch 67: Best model saved min loss 0.2865482568740845\n",
      "Epoch 68: Best model saved min loss 0.28589874505996704\n",
      "In epoch 70, loss: 0.2857973575592041\n",
      "Epoch 70: Best model saved min loss 0.2857973575592041\n",
      "Epoch 74: Best model saved min loss 0.2855261266231537\n",
      "In epoch 75, loss: 0.2853831350803375\n",
      "Epoch 75: Best model saved min loss 0.2853831350803375\n",
      "Epoch 77: Best model saved min loss 0.28478866815567017\n",
      "Epoch 78: Best model saved min loss 0.28458288311958313\n",
      "Epoch 79: Best model saved min loss 0.2835347354412079\n",
      "In epoch 80, loss: 0.28264111280441284\n",
      "Epoch 80: Best model saved min loss 0.28264111280441284\n",
      "Epoch 82: Best model saved min loss 0.28253504633903503\n",
      "Epoch 84: Best model saved min loss 0.28218093514442444\n",
      "In epoch 85, loss: 0.2826387882232666\n",
      "Epoch 87: Best model saved min loss 0.28134292364120483\n",
      "In epoch 90, loss: 0.28219735622406006\n",
      "Epoch 91: Best model saved min loss 0.2813047170639038\n",
      "Epoch 94: Best model saved min loss 0.28119736909866333\n",
      "In epoch 95, loss: 0.2818619906902313\n",
      "Epoch 96: Best model saved min loss 0.28074485063552856\n",
      "Epoch 97: Best model saved min loss 0.2802889049053192\n",
      "Epoch 99: Best model saved min loss 0.2799183130264282\n",
      "In epoch 100, loss: 0.28017351031303406\n",
      "Epoch 102: Best model saved min loss 0.2798144817352295\n",
      "In epoch 105, loss: 0.2802771329879761\n",
      "Epoch 108: Best model saved min loss 0.2797066867351532\n",
      "Epoch 109: Best model saved min loss 0.2793586254119873\n",
      "In epoch 110, loss: 0.2800210416316986\n",
      "Epoch 111: Best model saved min loss 0.27873075008392334\n",
      "In epoch 115, loss: 0.27906233072280884\n",
      "Epoch 116: Best model saved min loss 0.2783372402191162\n",
      "In epoch 120, loss: 0.27890828251838684\n",
      "In epoch 125, loss: 0.2806905210018158\n",
      "In epoch 130, loss: 0.281156450510025\n",
      "In epoch 135, loss: 0.2806347906589508\n",
      "In epoch 140, loss: 0.27903982996940613\n",
      "In epoch 145, loss: 0.27874261140823364\n",
      "Epoch 146: Best model saved min loss 0.2776663303375244\n",
      "In epoch 150, loss: 0.2773929536342621\n",
      "Epoch 150: Best model saved min loss 0.2773929536342621\n",
      "In epoch 155, loss: 0.2775927782058716\n",
      "Epoch 157: Best model saved min loss 0.2771739065647125\n",
      "In epoch 160, loss: 0.27816641330718994\n",
      "In epoch 165, loss: 0.27806442975997925\n",
      "Epoch 166: Best model saved min loss 0.2769745886325836\n",
      "Epoch 168: Best model saved min loss 0.27691972255706787\n",
      "In epoch 170, loss: 0.27732419967651367\n",
      "In epoch 175, loss: 0.27768588066101074\n",
      "In epoch 180, loss: 0.2775944471359253\n",
      "Epoch 182: Best model saved min loss 0.2768942415714264\n",
      "Epoch 183: Best model saved min loss 0.2768654227256775\n",
      "In epoch 185, loss: 0.2768234312534332\n",
      "Epoch 185: Best model saved min loss 0.2768234312534332\n",
      "Epoch 186: Best model saved min loss 0.2767665982246399\n",
      "Epoch 189: Best model saved min loss 0.27639469504356384\n",
      "In epoch 190, loss: 0.2767186164855957\n",
      "In epoch 195, loss: 0.2771507203578949\n",
      "In epoch 200, loss: 0.2765343189239502\n",
      "Epoch 203: Best model saved min loss 0.2760358154773712\n",
      "Epoch 204: Best model saved min loss 0.2758641839027405\n",
      "In epoch 205, loss: 0.27709195017814636\n",
      "In epoch 210, loss: 0.27640828490257263\n",
      "In epoch 215, loss: 0.2769216299057007\n",
      "Epoch 218: Best model saved min loss 0.27585169672966003\n",
      "In epoch 220, loss: 0.2764759659767151\n",
      "In epoch 225, loss: 0.2769737243652344\n",
      "In epoch 230, loss: 0.27669522166252136\n",
      "In epoch 235, loss: 0.2763058841228485\n",
      "In epoch 240, loss: 0.2768343687057495\n",
      "In epoch 245, loss: 0.27668264508247375\n",
      "In epoch 250, loss: 0.2763400971889496\n",
      "In epoch 255, loss: 0.27577367424964905\n",
      "Epoch 255: Best model saved min loss 0.27577367424964905\n",
      "In epoch 260, loss: 0.2763400971889496\n",
      "In epoch 265, loss: 0.2760825753211975\n",
      "In epoch 270, loss: 0.27635979652404785\n",
      "In epoch 275, loss: 0.2763653099536896\n",
      "In epoch 280, loss: 0.27627792954444885\n",
      "In epoch 285, loss: 0.27568870782852173\n",
      "Epoch 285: Best model saved min loss 0.27568870782852173\n",
      "In epoch 290, loss: 0.2759864330291748\n",
      "In epoch 295, loss: 0.2762008011341095\n",
      "In epoch 300, loss: 0.27605804800987244\n",
      "In epoch 305, loss: 0.27632901072502136\n",
      "In epoch 310, loss: 0.27654799818992615\n",
      "In epoch 315, loss: 0.27609118819236755\n",
      "Epoch 317: Best model saved min loss 0.27564045786857605\n",
      "In epoch 320, loss: 0.27567002177238464\n",
      "In epoch 325, loss: 0.2765345871448517\n",
      "In epoch 330, loss: 0.2759115993976593\n",
      "In epoch 335, loss: 0.275942862033844\n",
      "Epoch 338: Best model saved min loss 0.2755330502986908\n",
      "In epoch 340, loss: 0.2761130630970001\n",
      "In epoch 345, loss: 0.27595746517181396\n",
      "In epoch 350, loss: 0.27620670199394226\n",
      "In epoch 355, loss: 0.2757396996021271\n",
      "In epoch 360, loss: 0.27667662501335144\n",
      "In epoch 365, loss: 0.27603259682655334\n",
      "In epoch 370, loss: 0.2763179838657379\n",
      "In epoch 375, loss: 0.2762134373188019\n",
      "In epoch 380, loss: 0.2759797275066376\n",
      "In epoch 385, loss: 0.27564480900764465\n",
      "In epoch 390, loss: 0.2760475277900696\n",
      "In epoch 395, loss: 0.2757667899131775\n",
      "Epoch 397: Best model saved min loss 0.27541083097457886\n",
      "In epoch 400, loss: 0.2760416269302368\n",
      "In epoch 405, loss: 0.2754983603954315\n",
      "In epoch 410, loss: 0.2760682702064514\n",
      "Epoch 414: Best model saved min loss 0.275389164686203\n",
      "In epoch 415, loss: 0.2758917510509491\n",
      "In epoch 420, loss: 0.27592864632606506\n",
      "In epoch 425, loss: 0.27600961923599243\n",
      "Epoch 429: Best model saved min loss 0.2753858268260956\n",
      "In epoch 430, loss: 0.2762244939804077\n",
      "In epoch 435, loss: 0.2757702171802521\n",
      "In epoch 440, loss: 0.2756959795951843\n",
      "In epoch 445, loss: 0.2755250334739685\n",
      "In epoch 450, loss: 0.2760316729545593\n",
      "In epoch 455, loss: 0.2759968042373657\n",
      "In epoch 460, loss: 0.2759425938129425\n",
      "Epoch 461: Best model saved min loss 0.27535581588745117\n",
      "In epoch 465, loss: 0.2755303978919983\n",
      "In epoch 470, loss: 0.27553707361221313\n",
      "In epoch 475, loss: 0.2758185863494873\n",
      "Epoch 479: Best model saved min loss 0.275327205657959\n",
      "In epoch 480, loss: 0.2756623923778534\n",
      "Epoch 481: Best model saved min loss 0.27529314160346985\n",
      "In epoch 485, loss: 0.2756367623806\n",
      "In epoch 490, loss: 0.2757427394390106\n",
      "In epoch 495, loss: 0.2753972113132477\n",
      "In epoch 500, loss: 0.27533480525016785\n",
      "Epoch 503: Best model saved min loss 0.27526044845581055\n",
      "In epoch 505, loss: 0.2757923901081085\n",
      "In epoch 510, loss: 0.27538755536079407\n",
      "In epoch 515, loss: 0.27533042430877686\n",
      "In epoch 520, loss: 0.2758939564228058\n",
      "In epoch 525, loss: 0.2756693363189697\n",
      "In epoch 530, loss: 0.2754223346710205\n",
      "In epoch 535, loss: 0.2759547829627991\n",
      "Epoch 537: Best model saved min loss 0.27519330382347107\n",
      "In epoch 540, loss: 0.2755744457244873\n",
      "In epoch 545, loss: 0.27543362975120544\n",
      "In epoch 550, loss: 0.27528655529022217\n",
      "Epoch 552: Best model saved min loss 0.27519139647483826\n",
      "In epoch 555, loss: 0.2752660810947418\n",
      "In epoch 560, loss: 0.27565884590148926\n",
      "In epoch 565, loss: 0.2754579186439514\n",
      "Epoch 566: Best model saved min loss 0.27516183257102966\n",
      "Epoch 567: Best model saved min loss 0.2751540243625641\n",
      "In epoch 570, loss: 0.2754422426223755\n",
      "In epoch 575, loss: 0.27560824155807495\n",
      "In epoch 580, loss: 0.27520552277565\n",
      "Epoch 583: Best model saved min loss 0.27514001727104187\n",
      "In epoch 585, loss: 0.275232195854187\n",
      "In epoch 590, loss: 0.2754964828491211\n",
      "In epoch 595, loss: 0.27557143568992615\n",
      "In epoch 600, loss: 0.2756888270378113\n",
      "In epoch 605, loss: 0.2751602530479431\n",
      "Epoch 606: Best model saved min loss 0.27513235807418823\n",
      "In epoch 610, loss: 0.2752217948436737\n",
      "In epoch 615, loss: 0.2753870189189911\n",
      "In epoch 620, loss: 0.27527931332588196\n",
      "Epoch 621: Best model saved min loss 0.2751101851463318\n",
      "In epoch 625, loss: 0.27536696195602417\n",
      "In epoch 630, loss: 0.27530595660209656\n",
      "Epoch 632: Best model saved min loss 0.2750440835952759\n",
      "In epoch 635, loss: 0.27557650208473206\n",
      "Epoch 638: Best model saved min loss 0.2750416398048401\n",
      "In epoch 640, loss: 0.2755730450153351\n",
      "In epoch 645, loss: 0.27510273456573486\n",
      "In epoch 650, loss: 0.2753896415233612\n",
      "In epoch 655, loss: 0.27544739842414856\n",
      "In epoch 660, loss: 0.2753114700317383\n",
      "In epoch 665, loss: 0.2755748927593231\n",
      "Epoch 669: Best model saved min loss 0.2750244140625\n",
      "In epoch 670, loss: 0.2754723131656647\n",
      "In epoch 675, loss: 0.27529069781303406\n",
      "In epoch 680, loss: 0.27551719546318054\n",
      "Epoch 684: Best model saved min loss 0.2750110626220703\n",
      "In epoch 685, loss: 0.2752855718135834\n",
      "In epoch 690, loss: 0.27500656247138977\n",
      "Epoch 690: Best model saved min loss 0.27500656247138977\n",
      "In epoch 695, loss: 0.2753634750843048\n",
      "In epoch 700, loss: 0.27556270360946655\n",
      "In epoch 705, loss: 0.275344580411911\n",
      "In epoch 710, loss: 0.27498307824134827\n",
      "Epoch 710: Best model saved min loss 0.27498307824134827\n",
      "In epoch 715, loss: 0.27503490447998047\n",
      "In epoch 720, loss: 0.275134414434433\n",
      "Epoch 722: Best model saved min loss 0.27497199177742004\n",
      "In epoch 725, loss: 0.2752365171909332\n",
      "Epoch 728: Best model saved min loss 0.2749640941619873\n",
      "In epoch 730, loss: 0.27524375915527344\n",
      "In epoch 735, loss: 0.2751128375530243\n",
      "In epoch 740, loss: 0.27532759308815\n",
      "In epoch 745, loss: 0.2751017212867737\n",
      "In epoch 750, loss: 0.27545034885406494\n",
      "In epoch 755, loss: 0.27555587887763977\n",
      "In epoch 760, loss: 0.2752874195575714\n",
      "In epoch 765, loss: 0.27532386779785156\n",
      "Epoch 768: Best model saved min loss 0.2749503254890442\n",
      "In epoch 770, loss: 0.2751270830631256\n",
      "Epoch 773: Best model saved min loss 0.2748783826828003\n",
      "In epoch 775, loss: 0.2751982510089874\n",
      "In epoch 780, loss: 0.2750926613807678\n",
      "In epoch 785, loss: 0.2749563753604889\n",
      "In epoch 790, loss: 0.27516210079193115\n",
      "In epoch 795, loss: 0.2748473584651947\n",
      "Epoch 795: Best model saved min loss 0.2748473584651947\n",
      "Epoch 798: Best model saved min loss 0.2748081684112549\n",
      "In epoch 800, loss: 0.27482518553733826\n",
      "In epoch 805, loss: 0.2747880220413208\n",
      "Epoch 805: Best model saved min loss 0.2747880220413208\n",
      "In epoch 810, loss: 0.2750333547592163\n",
      "In epoch 815, loss: 0.2751072943210602\n",
      "In epoch 820, loss: 0.2752113342285156\n",
      "In epoch 825, loss: 0.27523642778396606\n",
      "In epoch 830, loss: 0.274766743183136\n",
      "Epoch 830: Best model saved min loss 0.274766743183136\n",
      "In epoch 835, loss: 0.2751058042049408\n",
      "In epoch 840, loss: 0.27493518590927124\n",
      "In epoch 845, loss: 0.27608799934387207\n",
      "In epoch 850, loss: 0.27526038885116577\n",
      "In epoch 855, loss: 0.2750808894634247\n",
      "In epoch 860, loss: 0.27497291564941406\n",
      "In epoch 865, loss: 0.27503979206085205\n",
      "In epoch 870, loss: 0.2747940719127655\n",
      "In epoch 875, loss: 0.27507439255714417\n",
      "In epoch 880, loss: 0.27511826157569885\n",
      "In epoch 885, loss: 0.2749136686325073\n",
      "In epoch 890, loss: 0.2748727798461914\n",
      "In epoch 895, loss: 0.2752234637737274\n",
      "In epoch 900, loss: 0.27482813596725464\n",
      "In epoch 905, loss: 0.27495795488357544\n",
      "Epoch 908: Best model saved min loss 0.2746897339820862\n",
      "In epoch 910, loss: 0.2749464809894562\n",
      "In epoch 915, loss: 0.2747538685798645\n",
      "In epoch 920, loss: 0.2749115526676178\n",
      "In epoch 925, loss: 0.2748051881790161\n",
      "Epoch 926: Best model saved min loss 0.27459394931793213\n",
      "In epoch 930, loss: 0.2748343050479889\n",
      "Epoch 934: Best model saved min loss 0.2745426893234253\n",
      "In epoch 935, loss: 0.2744978070259094\n",
      "Epoch 935: Best model saved min loss 0.2744978070259094\n",
      "In epoch 940, loss: 0.2746599614620209\n",
      "Epoch 942: Best model saved min loss 0.2744947075843811\n",
      "Epoch 944: Best model saved min loss 0.2744852602481842\n",
      "In epoch 945, loss: 0.274792343378067\n",
      "Epoch 947: Best model saved min loss 0.27445945143699646\n",
      "In epoch 950, loss: 0.27449411153793335\n",
      "In epoch 955, loss: 0.27493906021118164\n",
      "Epoch 959: Best model saved min loss 0.27444759011268616\n",
      "In epoch 960, loss: 0.2745991349220276\n",
      "In epoch 965, loss: 0.2745788097381592\n",
      "In epoch 970, loss: 0.27448874711990356\n",
      "Epoch 971: Best model saved min loss 0.27437323331832886\n",
      "In epoch 975, loss: 0.275336891412735\n",
      "In epoch 980, loss: 0.27448758482933044\n",
      "In epoch 985, loss: 0.2742970287799835\n",
      "Epoch 985: Best model saved min loss 0.2742970287799835\n",
      "In epoch 990, loss: 0.2747018039226532\n",
      "In epoch 995, loss: 0.27451640367507935\n",
      "Epoch 996: Best model saved min loss 0.2742050886154175\n",
      "Train AUC 0.9779040981677007\n",
      "Test AUC 0.9808412018278172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:02<00:00, 3878.01it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 7564.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.6648932129694571\n",
      "Test recall@100 0.6740290406710369\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "temp = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_image_data',\n",
    "                                                                                                                                          n_epochs=1000,\n",
    "                                                                                                                                          image_included=True,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt=None,patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Image Data along with dimensionality reduction ( UMAP )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'aggregator_type': 2, 'dropout': 0.42051995958759714, 'h_feats': 16.0, 'lr': 0.022254491166903718, 'n_epochs': 30.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_MODEL = 'inception'\n",
    "# model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'mean', 'dropout': 0, 'h_feats': 16, 'lr': 0.001},\n",
    "#                                                                                                                                           run_name=f'{IMAGE_MODEL}_image_data_umap',\n",
    "#                                                                                                                                           n_epochs=10,\n",
    "#                                                                                                                                           image_included=True,\n",
    "#                                                                                                                                           split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14388 6166\n",
      "In epoch 0, loss: 2402.720458984375\n",
      "Epoch 0: Best model saved min loss 2402.720458984375\n",
      "Epoch 1: Best model saved min loss 1656.411865234375\n",
      "Epoch 2: Best model saved min loss 345.5577392578125\n",
      "Epoch 3: Best model saved min loss 237.3142547607422\n",
      "In epoch 5, loss: 104.38713073730469\n",
      "Epoch 5: Best model saved min loss 104.38713073730469\n",
      "Epoch 6: Best model saved min loss 45.30768585205078\n",
      "Epoch 8: Best model saved min loss 20.57689094543457\n",
      "Epoch 9: Best model saved min loss 8.738787651062012\n",
      "In epoch 10, loss: 31.929183959960938\n",
      "Epoch 11: Best model saved min loss 2.333468437194824\n",
      "Epoch 14: Best model saved min loss 0.9150866270065308\n",
      "In epoch 15, loss: 2.307528018951416\n",
      "Epoch 17: Best model saved min loss 0.525970995426178\n",
      "Epoch 18: Best model saved min loss 0.46912452578544617\n",
      "Epoch 19: Best model saved min loss 0.4468097686767578\n",
      "In epoch 20, loss: 0.40396901965141296\n",
      "Epoch 20: Best model saved min loss 0.40396901965141296\n",
      "Epoch 21: Best model saved min loss 0.38775384426116943\n",
      "Epoch 22: Best model saved min loss 0.37171292304992676\n",
      "Epoch 23: Best model saved min loss 0.3573060631752014\n",
      "Epoch 24: Best model saved min loss 0.35063105821609497\n",
      "In epoch 25, loss: 0.33948007225990295\n",
      "Epoch 25: Best model saved min loss 0.33948007225990295\n",
      "Epoch 26: Best model saved min loss 0.33500880002975464\n",
      "Epoch 27: Best model saved min loss 0.33446717262268066\n",
      "In epoch 30, loss: 0.33686164021492004\n",
      "In epoch 35, loss: 0.33934783935546875\n",
      "In epoch 40, loss: 0.3364031910896301\n",
      "Epoch 42: Best model saved min loss 0.3341388404369354\n",
      "Epoch 43: Best model saved min loss 0.33288711309432983\n",
      "Epoch 44: Best model saved min loss 0.3315946161746979\n",
      "In epoch 45, loss: 0.3302892744541168\n",
      "Epoch 45: Best model saved min loss 0.3302892744541168\n",
      "Epoch 46: Best model saved min loss 0.328997403383255\n",
      "Epoch 47: Best model saved min loss 0.32774338126182556\n",
      "Epoch 48: Best model saved min loss 0.3265498876571655\n",
      "Epoch 49: Best model saved min loss 0.3254375159740448\n",
      "In epoch 50, loss: 0.32442498207092285\n",
      "Epoch 50: Best model saved min loss 0.32442498207092285\n",
      "Epoch 51: Best model saved min loss 0.323527991771698\n",
      "Epoch 52: Best model saved min loss 0.3227577209472656\n",
      "Epoch 53: Best model saved min loss 0.3221169114112854\n",
      "Epoch 54: Best model saved min loss 0.3215932548046112\n",
      "In epoch 55, loss: 0.3211517930030823\n",
      "Epoch 55: Best model saved min loss 0.3211517930030823\n",
      "Epoch 56: Best model saved min loss 0.3207300007343292\n",
      "Epoch 57: Best model saved min loss 0.3202463388442993\n",
      "Epoch 58: Best model saved min loss 0.3196325898170471\n",
      "Epoch 59: Best model saved min loss 0.3188753128051758\n",
      "In epoch 60, loss: 0.3180283308029175\n",
      "Epoch 60: Best model saved min loss 0.3180283308029175\n",
      "Epoch 61: Best model saved min loss 0.3171773850917816\n",
      "Epoch 62: Best model saved min loss 0.31639474630355835\n",
      "Epoch 63: Best model saved min loss 0.3157183527946472\n",
      "Epoch 64: Best model saved min loss 0.3151552379131317\n",
      "In epoch 65, loss: 0.3146924078464508\n",
      "Epoch 65: Best model saved min loss 0.3146924078464508\n",
      "Epoch 66: Best model saved min loss 0.31430843472480774\n",
      "Epoch 67: Best model saved min loss 0.3139806389808655\n",
      "Epoch 68: Best model saved min loss 0.3136897683143616\n",
      "Epoch 69: Best model saved min loss 0.3134221136569977\n",
      "In epoch 70, loss: 0.31317025423049927\n",
      "Epoch 70: Best model saved min loss 0.31317025423049927\n",
      "Epoch 71: Best model saved min loss 0.31293219327926636\n",
      "Epoch 72: Best model saved min loss 0.31270942091941833\n",
      "Epoch 73: Best model saved min loss 0.3125041723251343\n",
      "Epoch 74: Best model saved min loss 0.31231454014778137\n",
      "In epoch 75, loss: 0.3121321499347687\n",
      "Epoch 75: Best model saved min loss 0.3121321499347687\n",
      "Epoch 76: Best model saved min loss 0.3119455873966217\n",
      "Epoch 77: Best model saved min loss 0.31175094842910767\n",
      "Epoch 78: Best model saved min loss 0.31154507398605347\n",
      "Epoch 79: Best model saved min loss 0.3113415539264679\n",
      "In epoch 80, loss: 0.31114262342453003\n",
      "Epoch 80: Best model saved min loss 0.31114262342453003\n",
      "Epoch 81: Best model saved min loss 0.31094685196876526\n",
      "Epoch 82: Best model saved min loss 0.3107491135597229\n",
      "Epoch 83: Best model saved min loss 0.3105447292327881\n",
      "Epoch 84: Best model saved min loss 0.3103324770927429\n",
      "In epoch 85, loss: 0.3101145029067993\n",
      "Epoch 85: Best model saved min loss 0.3101145029067993\n",
      "Epoch 86: Best model saved min loss 0.309894859790802\n",
      "Epoch 87: Best model saved min loss 0.30967625975608826\n",
      "Epoch 88: Best model saved min loss 0.3094583749771118\n",
      "Epoch 89: Best model saved min loss 0.3092383146286011\n",
      "In epoch 90, loss: 0.30901360511779785\n",
      "Epoch 90: Best model saved min loss 0.30901360511779785\n",
      "Epoch 91: Best model saved min loss 0.3087848424911499\n",
      "Epoch 92: Best model saved min loss 0.3085547983646393\n",
      "Epoch 93: Best model saved min loss 0.3083258271217346\n",
      "Epoch 94: Best model saved min loss 0.3080984354019165\n",
      "In epoch 95, loss: 0.30787166953086853\n",
      "Epoch 95: Best model saved min loss 0.30787166953086853\n",
      "Epoch 96: Best model saved min loss 0.307644784450531\n",
      "Epoch 97: Best model saved min loss 0.30741798877716064\n",
      "Epoch 98: Best model saved min loss 0.30719271302223206\n",
      "Epoch 99: Best model saved min loss 0.3069708049297333\n",
      "Train AUC 0.977638726277141\n",
      "Test AUC 0.980804931020236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 7745.47it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 7722.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.667577469007049\n",
      "Test recall@100 0.675622048354127\n"
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_best_tuned_model',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=True,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':100,'n_neighbors':50,'min_dist':0.3},patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "2024/08/18 08:48:14 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2024/08/18 08:48:14 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2024/08/18 08:48:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2024/08/18 08:48:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\_distutils_hack\\__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node data shape : (10867, 40)\n",
      "Edges data shape : (20554, 2)\n",
      "Size of Input features : 38\n",
      "##########################\n",
      "Converting to biderctional Graph\n",
      "##########################\n",
      "27998 11999\n",
      "In epoch 0, loss: 6671.4052734375\n",
      "Epoch 0: Best model saved min loss 6671.4052734375\n",
      "Epoch 1: Best model saved min loss 5143.75146484375\n",
      "Epoch 3: Best model saved min loss 2271.85693359375\n",
      "In epoch 5, loss: 1742.8062744140625\n",
      "Epoch 5: Best model saved min loss 1742.8062744140625\n",
      "Epoch 7: Best model saved min loss 1108.091552734375\n",
      "Epoch 8: Best model saved min loss 667.4564208984375\n",
      "In epoch 10, loss: 430.9026794433594\n",
      "Epoch 10: Best model saved min loss 430.9026794433594\n",
      "Epoch 13: Best model saved min loss 264.24749755859375\n",
      "In epoch 15, loss: 231.84072875976562\n",
      "Epoch 15: Best model saved min loss 231.84072875976562\n",
      "Epoch 17: Best model saved min loss 131.11282348632812\n",
      "Epoch 19: Best model saved min loss 102.09928894042969\n",
      "In epoch 20, loss: 56.513126373291016\n",
      "Epoch 20: Best model saved min loss 56.513126373291016\n",
      "Epoch 23: Best model saved min loss 53.069602966308594\n",
      "In epoch 25, loss: 97.1092758178711\n",
      "Epoch 26: Best model saved min loss 13.80074405670166\n",
      "Epoch 27: Best model saved min loss 11.4705171585083\n",
      "In epoch 30, loss: 11.393693923950195\n",
      "Epoch 30: Best model saved min loss 11.393693923950195\n",
      "Epoch 31: Best model saved min loss 2.455256223678589\n",
      "Epoch 32: Best model saved min loss 1.4820489883422852\n",
      "Epoch 33: Best model saved min loss 1.126325011253357\n",
      "Epoch 34: Best model saved min loss 0.9850524067878723\n",
      "In epoch 35, loss: 0.5785143375396729\n",
      "Epoch 35: Best model saved min loss 0.5785143375396729\n",
      "Epoch 37: Best model saved min loss 0.533068060874939\n",
      "Epoch 39: Best model saved min loss 0.44101282954216003\n",
      "In epoch 40, loss: 0.40955427289009094\n",
      "Epoch 40: Best model saved min loss 0.40955427289009094\n",
      "Epoch 42: Best model saved min loss 0.3868426978588104\n",
      "Epoch 43: Best model saved min loss 0.38258716464042664\n",
      "Epoch 44: Best model saved min loss 0.37490740418434143\n",
      "In epoch 45, loss: 0.3691823482513428\n",
      "Epoch 45: Best model saved min loss 0.3691823482513428\n",
      "Epoch 46: Best model saved min loss 0.36715203523635864\n",
      "Epoch 47: Best model saved min loss 0.36113661527633667\n",
      "Epoch 48: Best model saved min loss 0.35856741666793823\n",
      "Epoch 49: Best model saved min loss 0.3567500710487366\n",
      "In epoch 50, loss: 0.3537464141845703\n",
      "Epoch 50: Best model saved min loss 0.3537464141845703\n",
      "Epoch 52: Best model saved min loss 0.3510923683643341\n",
      "Epoch 53: Best model saved min loss 0.35056057572364807\n",
      "Epoch 54: Best model saved min loss 0.346690833568573\n",
      "In epoch 55, loss: 0.34709522128105164\n",
      "Epoch 56: Best model saved min loss 0.34332722425460815\n",
      "Epoch 57: Best model saved min loss 0.3390653133392334\n",
      "Epoch 58: Best model saved min loss 0.33873042464256287\n",
      "Epoch 59: Best model saved min loss 0.3362395763397217\n",
      "In epoch 60, loss: 0.331815242767334\n",
      "Epoch 60: Best model saved min loss 0.331815242767334\n",
      "Epoch 61: Best model saved min loss 0.32846829295158386\n",
      "Epoch 62: Best model saved min loss 0.3263593912124634\n",
      "Epoch 63: Best model saved min loss 0.3243184983730316\n",
      "In epoch 65, loss: 0.3198266327381134\n",
      "Epoch 65: Best model saved min loss 0.3198266327381134\n",
      "Epoch 66: Best model saved min loss 0.31911182403564453\n",
      "Epoch 67: Best model saved min loss 0.3179551064968109\n",
      "Epoch 68: Best model saved min loss 0.31739342212677\n",
      "Epoch 69: Best model saved min loss 0.3164062201976776\n",
      "In epoch 70, loss: 0.31567099690437317\n",
      "Epoch 70: Best model saved min loss 0.31567099690437317\n",
      "Epoch 71: Best model saved min loss 0.31296825408935547\n",
      "Epoch 72: Best model saved min loss 0.3116942346096039\n",
      "Epoch 73: Best model saved min loss 0.31062301993370056\n",
      "Epoch 74: Best model saved min loss 0.3089495897293091\n",
      "In epoch 75, loss: 0.30743497610092163\n",
      "Epoch 75: Best model saved min loss 0.30743497610092163\n",
      "Epoch 78: Best model saved min loss 0.3055638372898102\n",
      "Epoch 79: Best model saved min loss 0.30532070994377136\n",
      "In epoch 80, loss: 0.3049825131893158\n",
      "Epoch 80: Best model saved min loss 0.3049825131893158\n",
      "Epoch 81: Best model saved min loss 0.3045042157173157\n",
      "Epoch 82: Best model saved min loss 0.3043529987335205\n",
      "Epoch 83: Best model saved min loss 0.3025234341621399\n",
      "In epoch 85, loss: 0.3011949360370636\n",
      "Epoch 85: Best model saved min loss 0.3011949360370636\n",
      "Epoch 86: Best model saved min loss 0.30042293667793274\n",
      "Epoch 89: Best model saved min loss 0.2987404465675354\n",
      "In epoch 90, loss: 0.2982206642627716\n",
      "Epoch 90: Best model saved min loss 0.2982206642627716\n",
      "Epoch 91: Best model saved min loss 0.297282338142395\n",
      "Epoch 93: Best model saved min loss 0.29618439078330994\n",
      "In epoch 95, loss: 0.2949962615966797\n",
      "Epoch 95: Best model saved min loss 0.2949962615966797\n",
      "Epoch 98: Best model saved min loss 0.29424959421157837\n",
      "Train AUC 0.9642177104947605\n",
      "Test AUC 0.9633748509239398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10867/10867 [00:01<00:00, 7942.48it/s]\n",
      "100%|██████████| 10867/10867 [00:01<00:00, 8076.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@100 0.608480661426549\n",
      "Test recall@100 0.5866506245706534\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m IMAGE_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minception\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMAGE_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maggregator_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.42051995958759714\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh_feats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.022254491166903718\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mIMAGE_MODEL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_umap_bidirectional\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43mimage_included\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                                                                                          \u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mumap_dt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_components\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_neighbors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_dist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43monly_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43muse_bidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Masters upgrad\\clothing recommendation\\notebooks\\util.py:378\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(mlflow, image_model, run_name, n_epochs, model_params, image_included, split_ratio, umap_dt, k, patience, only_image, use_bidirectional)\u001b[0m\n\u001b[0;32m    376\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(model_params)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m umap_dt:\n\u001b[1;32m--> 378\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_dt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(g, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    380\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./graph.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\tracking\\fluent.py:921\u001b[0m, in \u001b[0;36mlog_params\u001b[1;34m(params, synchronous, run_id)\u001b[0m\n\u001b[0;32m    919\u001b[0m params_arr \u001b[38;5;241m=\u001b[39m [Param(key, \u001b[38;5;28mstr\u001b[39m(value)) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m    920\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\tracking\\client.py:1832\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[1;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;124;03mLog multiple metrics, params, and/or tags.\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \n\u001b[0;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1830\u001b[0m     synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m   1831\u001b[0m )\n\u001b[1;32m-> 1832\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[0;32m   1834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:715\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[1;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[0;32m    712\u001b[0m metrics \u001b[38;5;241m=\u001b[39m metrics[metrics_batch_size:]\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags_batch\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     run_operations_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_batch_async(\n\u001b[0;32m    721\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    725\u001b[0m         )\n\u001b[0;32m    726\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:535\u001b[0m, in \u001b[0;36mRestStore.log_batch\u001b[1;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[0;32m    531\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[0;32m    532\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m    533\u001b[0m     LogBatch(metrics\u001b[38;5;241m=\u001b[39mmetric_protos, params\u001b[38;5;241m=\u001b[39mparam_protos, tags\u001b[38;5;241m=\u001b[39mtag_protos, run_id\u001b[38;5;241m=\u001b[39mrun_id)\n\u001b[0;32m    534\u001b[0m )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogBatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:81\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[0;32m     79\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     80\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:302\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m--> 302\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m    304\u001b[0m response \u001b[38;5;241m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[0;32m    305\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:129\u001b[0m, in \u001b[0;36mhttp_request\u001b[1;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_hostname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[0;32m    130\u001b[0m         method,\n\u001b[0;32m    131\u001b[0m         url,\n\u001b[0;32m    132\u001b[0m         max_retries,\n\u001b[0;32m    133\u001b[0m         backoff_factor,\n\u001b[0;32m    134\u001b[0m         backoff_jitter,\n\u001b[0;32m    135\u001b[0m         retry_codes,\n\u001b[0;32m    136\u001b[0m         raise_on_status,\n\u001b[0;32m    137\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    138\u001b[0m         verify\u001b[38;5;241m=\u001b[39mhost_creds\u001b[38;5;241m.\u001b[39mverify,\n\u001b[0;32m    139\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    140\u001b[0m         respect_retry_after_header\u001b[38;5;241m=\u001b[39mrespect_retry_after_header,\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m to:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with timeout exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m To increase the timeout, set the environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m to a larger value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mto\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\mlflow\\utils\\request_utils.py:228\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[1;34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m env_value \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_ALLOW_HTTP_REDIRECTS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    226\u001b[0m allow_redirects \u001b[38;5;241m=\u001b[39m env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method, url, allow_redirects\u001b[38;5;241m=\u001b[39mallow_redirects, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    946\u001b[0m     retries\u001b[38;5;241m.\u001b[39msleep(response)\n\u001b[0;32m    947\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m--> 948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    949\u001b[0m         method,\n\u001b[0;32m    950\u001b[0m         url,\n\u001b[0;32m    951\u001b[0m         body,\n\u001b[0;32m    952\u001b[0m         headers,\n\u001b[0;32m    953\u001b[0m         retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    954\u001b[0m         redirect\u001b[38;5;241m=\u001b[39mredirect,\n\u001b[0;32m    955\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39massert_same_host,\n\u001b[0;32m    956\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    957\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    958\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    959\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    960\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    961\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    962\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    946\u001b[0m     retries\u001b[38;5;241m.\u001b[39msleep(response)\n\u001b[0;32m    947\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m--> 948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    949\u001b[0m         method,\n\u001b[0;32m    950\u001b[0m         url,\n\u001b[0;32m    951\u001b[0m         body,\n\u001b[0;32m    952\u001b[0m         headers,\n\u001b[0;32m    953\u001b[0m         retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    954\u001b[0m         redirect\u001b[38;5;241m=\u001b[39mredirect,\n\u001b[0;32m    955\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39massert_same_host,\n\u001b[0;32m    956\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    957\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    958\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    959\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    960\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    961\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    962\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "    \u001b[1;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 948 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    946\u001b[0m     retries\u001b[38;5;241m.\u001b[39msleep(response)\n\u001b[0;32m    947\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[1;32m--> 948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    949\u001b[0m         method,\n\u001b[0;32m    950\u001b[0m         url,\n\u001b[0;32m    951\u001b[0m         body,\n\u001b[0;32m    952\u001b[0m         headers,\n\u001b[0;32m    953\u001b[0m         retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    954\u001b[0m         redirect\u001b[38;5;241m=\u001b[39mredirect,\n\u001b[0;32m    955\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39massert_same_host,\n\u001b[0;32m    956\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    957\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    958\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    959\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    960\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    961\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    962\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:946\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    945\u001b[0m response\u001b[38;5;241m.\u001b[39mdrain_conn()\n\u001b[1;32m--> 946\u001b[0m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    949\u001b[0m     method,\n\u001b[0;32m    950\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    964\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\util\\retry.py:359\u001b[0m, in \u001b[0;36mRetry.sleep\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m slept:\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\util\\retry.py:343\u001b[0m, in \u001b[0;36mRetry._sleep_backoff\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backoff \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IMAGE_MODEL = 'inception'\n",
    "model,g,nodes,edges,train_pos_u, train_pos_v,test_pos_u, test_pos_v,train_neg_u, train_neg_v,test_neg_u, test_neg_v,train_g,test_g = train_model(mlflow=mlflow,image_model=IMAGE_MODEL,model_params = {'aggregator_type': 'lstm', 'dropout': 0.42051995958759714, 'h_feats': 16, 'lr': 0.022254491166903718},\n",
    "                                                                                                                                          run_name=f'{IMAGE_MODEL}_umap_bidirectional',\n",
    "                                                                                                                                          n_epochs=100,\n",
    "                                                                                                                                          image_included=True,\n",
    "                                                                                                                                          split_ratio=0.3,umap_dt={'n_components':1,'n_neighbors':50,'min_dist':0.3},patience=100,only_image=True,use_bidirectional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
